{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0e1c7dafd5b49bc8fbab287e9c3adbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13c6fa37bae04b929d72810b8c6563c3",
              "IPY_MODEL_b4a130843e844feeb87b2860283f79b4",
              "IPY_MODEL_f10f7618a09246a0b982ed2a68741055"
            ],
            "layout": "IPY_MODEL_907a64a0a4864a5692357a595eec78f1"
          }
        },
        "13c6fa37bae04b929d72810b8c6563c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f7d09817914bb5ad6330ff1dfec570",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_89da3e74096d473dbd94fd69cd68d315",
            "value": "100%"
          }
        },
        "b4a130843e844feeb87b2860283f79b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c30b65198b734560b6aa3b0f38b5fdfc",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c8421fcdff4487b8f59fd7d034c5b4b",
            "value": 3
          }
        },
        "f10f7618a09246a0b982ed2a68741055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f34f1b4e1275499aa9ae0a83d53680e7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_260877e0fbba4dc283f156d2c453a20d",
            "value": "â€‡3/3â€‡[00:17&lt;00:00,â€‡â€‡5.48s/it]"
          }
        },
        "907a64a0a4864a5692357a595eec78f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f7d09817914bb5ad6330ff1dfec570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89da3e74096d473dbd94fd69cd68d315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c30b65198b734560b6aa3b0f38b5fdfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8421fcdff4487b8f59fd7d034c5b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f34f1b4e1275499aa9ae0a83d53680e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "260877e0fbba4dc283f156d2c453a20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ac41de3429c4381ae04debaa657c5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6cdae5f898946f595c8f8235af0e627",
              "IPY_MODEL_7161a11dd27f49e3bc8f64f2c6ea74e1",
              "IPY_MODEL_ff60568d95814ca5bbedd1a8527c0a5a"
            ],
            "layout": "IPY_MODEL_e7aa8e045bb44bc89d609f757bc632a4"
          }
        },
        "d6cdae5f898946f595c8f8235af0e627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de5428f5dad64c51901ccef55fc0ef38",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d655d011b8ef4992bc193ac582c07ead",
            "value": "100%"
          }
        },
        "7161a11dd27f49e3bc8f64f2c6ea74e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35645e4101684ae0b660fe3bf94ba357",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13adb16b53b44491a8c4d6bdffa447fe",
            "value": 1
          }
        },
        "ff60568d95814ca5bbedd1a8527c0a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15765081540d434280fadf2db7cad78c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_56dca4666247412b9808714ce4805fea",
            "value": "â€‡1/1â€‡[00:01&lt;00:00,â€‡â€‡1.04s/it]"
          }
        },
        "e7aa8e045bb44bc89d609f757bc632a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de5428f5dad64c51901ccef55fc0ef38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d655d011b8ef4992bc193ac582c07ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35645e4101684ae0b660fe3bf94ba357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13adb16b53b44491a8c4d6bdffa447fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15765081540d434280fadf2db7cad78c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56dca4666247412b9808714ce4805fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23b25ce5aa0349f8b04bd2ecc7ccf53d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdbcb4e18d9b4a09810dbdf8d86918ab",
              "IPY_MODEL_22e2fcc0358c43dcafbb20808eb9bd6a",
              "IPY_MODEL_8217af31d5874e8e9f28134fd2b81803"
            ],
            "layout": "IPY_MODEL_06e9d6d0bb4841e8b71b7330ab6e0555"
          }
        },
        "bdbcb4e18d9b4a09810dbdf8d86918ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_670513faf9124f5dbb52320659fa2685",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0e51603c5e1641dc9b8e1fcb24c8e7b0",
            "value": "100%"
          }
        },
        "22e2fcc0358c43dcafbb20808eb9bd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9495152d427d4d64b038d978418f84ef",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2ba71fc40ee4a6f8d43586a1a9dde6a",
            "value": 1
          }
        },
        "8217af31d5874e8e9f28134fd2b81803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45a8bab3ff12426b866765869bd1d133",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1aabc9ad52fe48988266b82b171044af",
            "value": "â€‡1/1â€‡[00:00&lt;00:00,â€‡â€‡4.10it/s]"
          }
        },
        "06e9d6d0bb4841e8b71b7330ab6e0555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670513faf9124f5dbb52320659fa2685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e51603c5e1641dc9b8e1fcb24c8e7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9495152d427d4d64b038d978418f84ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ba71fc40ee4a6f8d43586a1a9dde6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45a8bab3ff12426b866765869bd1d133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aabc9ad52fe48988266b82b171044af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqK_u-R5hWf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49206ec9-466d-48c5-cc5e-e7143ccc1d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Environment initialized\n",
            "Project folder: medical_rag_bot/\n",
            "Documents folder: medical_rag_bot/docs/\n"
          ]
        }
      ],
      "source": [
        "#environment setuu\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# Clean output - suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "os.makedirs('medical_rag_bot/docs', exist_ok=True)\n",
        "os.chdir('/content/medical_rag_bot')\n",
        "\n",
        "print(\"âœ… Environment initialized\")\n",
        "print(\"Project folder: medical_rag_bot/\")\n",
        "print(\"Documents folder: medical_rag_bot/docs/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Required Packages\n",
        "\n",
        "print(\"ğŸ“¥ Installing OpenAI packages...\")\n",
        "\n",
        "!pip install -q openai langchain langchain-openai chromadb PyMuPDF langchain-community\n",
        "\n",
        "print(\"âœ… All packages installed successfully!\")\n",
        "print(\"ğŸ”— Installed packages:\")\n",
        "print(\"   â€¢ openai - OpenAI API client\")\n",
        "print(\"   â€¢ langchain - LLM framework\")\n",
        "print(\"   â€¢ langchain-openai - OpenAI integration\")\n",
        "print(\"   â€¢ chromadb - Vector database\")\n",
        "print(\"   â€¢ PyMuPDF - PDF processing\")\n",
        "print(\"   â€¢ langchain-community - Additional tools\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke5SaTJ4hcPG",
        "outputId": "8784a8bd-8002-4484-9167-fbedc440020d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Installing OpenAI packages...\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… All packages installed successfully!\n",
            "ğŸ”— Installed packages:\n",
            "   â€¢ openai - OpenAI API client\n",
            "   â€¢ langchain - LLM framework\n",
            "   â€¢ langchain-openai - OpenAI integration\n",
            "   â€¢ chromadb - Vector database\n",
            "   â€¢ PyMuPDF - PDF processing\n",
            "   â€¢ langchain-community - Additional tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "print(\"ğŸ“š Loading libraries...\")\n",
        "\n",
        "# Core OpenAI imports\n",
        "import openai\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "# LangChain components\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Utilities\n",
        "from getpass import getpass\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoZ01LXQhkq7",
        "outputId": "9d87de5b-9d08-4d6e-9e9d-aa42b944e573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“š Loading libraries...\n",
            "âœ… All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure OpenAI API\n",
        "\n",
        "OPENAI_API_KEY = getpass(\"Enter your OpenAI API key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "print(\"âœ… OpenAI API configured successfully!\")\n",
        "print(\"ğŸ”’ API key securely stored in environment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvox8A4thyeU",
        "outputId": "8d6559df-2f81-4b0b-95f0-e9709425d505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ… OpenAI API configured successfully!\n",
            "ğŸ”’ API key securely stored in environment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Document Upload\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print(\"ğŸ“‹ Medical Document Upload\")\n",
        "print(\"â”€\" * 40)\n",
        "print(\"ğŸ“ Please upload your medical PDF files\")\n",
        "# print(\"ğŸ’¡ Supported format: PDF only\")\n",
        "# print(\"âš ï¸  Large files may take longer to process\")\n",
        "# print(\"â”€\" * 40)\n",
        "\n",
        "# File upload interface\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process uploaded files\n",
        "uploaded_count = 0\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.pdf'):\n",
        "        shutil.move(filename, f'docs/{filename}')\n",
        "        print(f\"âœ… Successfully uploaded: {filename}\")\n",
        "        uploaded_count += 1\n",
        "    else:\n",
        "        print(f\"âŒ Skipped non-PDF file: {filename}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Upload Summary: {uploaded_count} PDF file(s) uploaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "jnwdHhg5iDR3",
        "outputId": "6fac5302-a828-4c63-d26e-a50f3a708ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‹ Medical Document Upload\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ“ Please upload your medical PDF files\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-89559d05-fe4d-4e3a-b3c8-eea5630b445d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-89559d05-fe4d-4e3a-b3c8-eea5630b445d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Medical_book.pdf to Medical_book.pdf\n",
            "âœ… Successfully uploaded: Medical_book.pdf\n",
            "\n",
            "ğŸ“Š Upload Summary: 1 PDF file(s) uploaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Document Processing & Text Extraction\n",
        "\n",
        "print(\"ğŸ“– Processing Medical Documents\")\n",
        "print(\"â”€\" * 40)\n",
        "\n",
        "documents = []\n",
        "total_pages = 0\n",
        "\n",
        "# Process each PDF file\n",
        "for filename in os.listdir(\"docs\"):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        print(f\"ğŸ”„ Processing: {filename}\")\n",
        "\n",
        "        # Load PDF and extract text\n",
        "        loader = PyMuPDFLoader(f\"docs/{filename}\")\n",
        "        docs = loader.load()\n",
        "        documents.extend(docs)\n",
        "\n",
        "        pages = len(docs)\n",
        "        total_pages += pages\n",
        "        print(f\"   ğŸ“„ Extracted {pages} pages\")\n",
        "\n",
        "print(\"â”€\" * 40)\n",
        "print(f\"ğŸ“Š Processing Summary:\")\n",
        "print(f\"   ğŸ“š Total files processed: {len([f for f in os.listdir('docs') if f.endswith('.pdf')])}\")\n",
        "print(f\"   ğŸ“„ Total pages extracted: {total_pages}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53BnPwnYiZaz",
        "outputId": "7f85621a-73e7-4efa-8411-3f92e488e7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“– Processing Medical Documents\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ”„ Processing: Medical_book.pdf\n",
            "   ğŸ“„ Extracted 637 pages\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ“Š Processing Summary:\n",
            "   ğŸ“š Total files processed: 1\n",
            "   ğŸ“„ Total pages extracted: 637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting docs into chunks\n",
        "if documents:\n",
        "    # Split documents into chunks for better processing\n",
        "    print(f\"\\nğŸ”ª Splitting documents into chunks...\")\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1200,    # Each chunk ~1200 characters\n",
        "        chunk_overlap=200   # 200 character overlap for context\n",
        "    )\n",
        "    chunks = splitter.split_documents(documents)\n",
        "    print(f\"âœ… Created {len(chunks)} text chunks\")\n",
        "    print(f\"ğŸ’¡ Chunk size: ~1200 characters each\")\n",
        "else:\n",
        "    print(\"âŒ No documents found! Please upload PDF files first.\")\n",
        "    chunks = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUOSB9Qai0v-",
        "outputId": "690c35fd-d476-4089-f8ef-b659734bb308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”ª Splitting documents into chunks...\n",
            "âœ… Created 2784 text chunks\n",
            "ğŸ’¡ Chunk size: ~1200 characters each\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector Database Creation\n",
        "\n",
        "print(\"ğŸ§¬ Creating Vector Database with OpenAI\")\n",
        "print(\"â”€\" * 40)\n",
        "print(\"ğŸ”„ Converting text to embeddings...\")\n",
        "\n",
        "# Create OpenAI embeddings model\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",  # Cost-effective embedding model\n",
        "    show_progress_bar=True           # Show progress during embedding\n",
        ")\n",
        "\n",
        "# Create vector database\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"medical_db\"\n",
        ")\n",
        "\n",
        "# Create retriever for similarity search\n",
        "retriever = vectordb.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 3}\n",
        ")\n",
        "\n",
        "print(\"âœ… Vector database created successfully!\")\n",
        "print(\"ğŸ’¾ Database saved to: medical_db/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "referenced_widgets": [
            "e0e1c7dafd5b49bc8fbab287e9c3adbc",
            "13c6fa37bae04b929d72810b8c6563c3",
            "b4a130843e844feeb87b2860283f79b4",
            "f10f7618a09246a0b982ed2a68741055",
            "907a64a0a4864a5692357a595eec78f1",
            "07f7d09817914bb5ad6330ff1dfec570",
            "89da3e74096d473dbd94fd69cd68d315",
            "c30b65198b734560b6aa3b0f38b5fdfc",
            "6c8421fcdff4487b8f59fd7d034c5b4b",
            "f34f1b4e1275499aa9ae0a83d53680e7",
            "260877e0fbba4dc283f156d2c453a20d"
          ]
        },
        "id": "7gAGamuzi-RL",
        "outputId": "cb53dea9-ea6a-4112-f540-1aeabd9b27fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§¬ Creating Vector Database with OpenAI\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ”„ Converting text to embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0e1c7dafd5b49bc8fbab287e9c3adbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Vector database created successfully!\n",
            "ğŸ’¾ Database saved to: medical_db/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Language Model Setup\n",
        "\n",
        "print(\"ğŸ¤– Initializing OpenAI Language Model\")\n",
        "print(\"â”€\" * 40)\n",
        "\n",
        "# Initialize ChatGPT model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",        # Cost-effective, high-performance model\n",
        "    temperature=0.2,            # Low temperature for consistent, focused responses\n",
        "    max_tokens=1000,            # Reasonable response length\n",
        "    timeout=30                  # 30 second timeout\n",
        ")\n",
        "\n",
        "print(\"âœ… Language model initialized successfully!\")\n",
        "print(\"ğŸ§  Model: GPT-4o-mini (optimized for medical queries)\")\n",
        "# print(\"ğŸŒ¡ï¸  Temperature: 0.2 (focused responses)\")\n",
        "# print(\"ğŸ’¬ Max tokens: 1000 per response\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw6hAveMjSkk",
        "outputId": "4acfed5d-0cb8-40ab-e46a-f376ca683d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¤– Initializing OpenAI Language Model\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "âœ… Language model initialized successfully!\n",
            "ğŸ§  Model: GPT-4o-mini (optimized for medical queries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caching System Setup\n",
        "\n",
        "print(\"ğŸ’¾ Setting up Response Caching System\")\n",
        "print(\"â”€\" * 40)\n",
        "\n",
        "# Simple in-memory cache to avoid repeated API calls\n",
        "cache = {}\n",
        "\n",
        "def cached_hybrid_query(query: str):\n",
        "    \"\"\"\n",
        "    Cache responses to avoid repeated API calls and save costs\n",
        "\n",
        "    Args:\n",
        "        query (str): User's medical question\n",
        "\n",
        "    Returns:\n",
        "        str: Cached or newly generated response\n",
        "    \"\"\"\n",
        "    cache_key = query.lower().strip()\n",
        "\n",
        "    if cache_key in cache:\n",
        "        print(\"Using cached response! (No API cost)\")\n",
        "        return cache[cache_key]\n",
        "\n",
        "    print(\"ğŸ”„ Processing new query... \")\n",
        "    result = hybrid_query(query)\n",
        "\n",
        "    cache[cache_key] = result\n",
        "    return result\n",
        "\n",
        "def clear_cache():\n",
        "    \"\"\"Clear all cached responses\"\"\"\n",
        "    global cache\n",
        "    cache = {}\n",
        "    print(\"ğŸ—‘ï¸ Cache cleared! All future questions will use fresh API calls.\")\n",
        "\n",
        "print(\"âœ… Caching system ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-1Ww5JrjtMw",
        "outputId": "9fb09e5d-9a54-48f9-aee5-ceed0faac99a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ Setting up Response Caching System\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "âœ… Caching system ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieval-Augmented Generation (RAG) Chain\n",
        "\n",
        "print(\"ğŸ”— Creating Retrieval-Augmented Generation Chain\")\n",
        "print(\"â”€\" * 40)\n",
        "\n",
        "# Create RetrievalQA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,                        # Our ChatGPT model\n",
        "    chain_type=\"stuff\",             # Combine all retrieved docs in one prompt\n",
        "    retriever=retriever,            # Our vector database retriever\n",
        "    return_source_documents=True,   # Return sources for citations\n",
        "    verbose=False                   # Clean output\n",
        ")\n",
        "\n",
        "print(\"âœ… RAG chain created successfully!\")\n",
        "print(\"ğŸ” Chain type: 'stuff' (combines all relevant documents)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CE7Yi95kA_Y",
        "outputId": "7f6120a3-d7b5-4919-c711-6a303fc1a4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”— Creating Retrieval-Augmented Generation Chain\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "âœ… RAG chain created successfully!\n",
            "ğŸ” Chain type: 'stuff' (combines all relevant documents)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query Processing Functions\n",
        "\n",
        "def ask_llm_first(query: str):\n",
        "    \"\"\"Try OpenAI directly. Return None if uncertain.\"\"\"\n",
        "    system_prompt = f\"\"\"\n",
        "    You are a medical AI assistant. Answer only if you are confident.\n",
        "    If you don't know, reply exactly: \"I don't know.\"\n",
        "\n",
        "    Question: {query}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(system_prompt)\n",
        "    content = response.content if hasattr(response, \"content\") else str(response)\n",
        "\n",
        "    if \"i don't know\" in content.lower():\n",
        "        return None\n",
        "    return content\n",
        "\n",
        "\n",
        "def ask_with_rag(query: str):\n",
        "    \"\"\"\n",
        "    Ask a question using RAG and return the answer with clean source citations.\n",
        "    Page numbers are corrected for human readability.\n",
        "    \"\"\"\n",
        "    # Get answer from QA chain\n",
        "    result = qa_chain.invoke({\"query\": query})\n",
        "    answer = result.get(\"result\", \"No answer found.\")\n",
        "\n",
        "    sources = []\n",
        "    for doc in result.get(\"source_documents\", []):\n",
        "        file = os.path.basename(doc.metadata.get(\"source\", \"Medical_book.pdf\"))\n",
        "\n",
        "        # Get page number and shift to human-readable\n",
        "        page = doc.metadata.get(\"page\", \"?\")\n",
        "        try:\n",
        "            page = int(page) + 1\n",
        "        except:\n",
        "            page = \"?\"\n",
        "        sources.append(f\"{file}, p.{page}\")\n",
        "    sources = list(dict.fromkeys(sources))\n",
        "\n",
        "    return answer, sources\n",
        "\n",
        "\n",
        "def hybrid_query(query: str):\n",
        "    \"\"\"Main function: Try LLM first â†’ fallback to RAG.\"\"\"\n",
        "    llm_answer = ask_llm_first(query)\n",
        "    if llm_answer:\n",
        "        return f\"ğŸ§  **OPENAI**: {llm_answer}\"\n",
        "    else:\n",
        "        rag_answer, sources = ask_with_rag(query)\n",
        "        source_list = \", \".join([os.path.basename(s) for s in sources])\n",
        "        return f\"ğŸ“š **RAG**: {rag_answer}\\n\\nğŸ“ **Sources**: {source_list}\"\n",
        "\n",
        "print(\"âœ… Query functions ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4NC443NkQvl",
        "outputId": "d4d495e6-fa7e-4574-b268-d96ad5c623e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Query functions ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive Command-Line Chat\n",
        "\n",
        "def start_chat():\n",
        "    \"\"\"Interactive command-line medical chatbot\"\"\"\n",
        "    print(\"ğŸ¥ Medical Chatbot with OpenAI\")\n",
        "    print(\"â•\" * 40)\n",
        "    print(\"ğŸ’¡ Commands: 'exit' to quit, 'cost' for usage, 'cache' for history\")\n",
        "    print(\"\")\n",
        "\n",
        "    while True:\n",
        "        user_q = input(\"ğŸ’¬ **You**: \").strip()\n",
        "\n",
        "        if user_q.lower() == \"exit\":\n",
        "            print(\"ğŸ‘‹ Goodbye!\")\n",
        "            break\n",
        "        elif user_q.lower() == \"cost\":\n",
        "            print(f\"ğŸ’° Questions answered: {len(cache)}, Estimated cost: ${len(cache) * 0.005:.3f}\")\n",
        "            continue\n",
        "        elif user_q.lower() == \"cache\":\n",
        "            print(f\"ğŸ’¾ Cached questions: {len(cache)}\")\n",
        "            continue\n",
        "        elif not user_q:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            answer = cached_hybrid_query(user_q)\n",
        "            print(f\"\\n\\n{answer}\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error: {e}\")\n",
        "\n",
        "print(\"âœ… Command-line chat ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sMbLNT9k9cI",
        "outputId": "5454a0ee-db38-4ea6-b188-38d509df3537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Command-line chat ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Interactive Chat\n",
        "\n",
        "start_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841,
          "referenced_widgets": [
            "9ac41de3429c4381ae04debaa657c5b6",
            "d6cdae5f898946f595c8f8235af0e627",
            "7161a11dd27f49e3bc8f64f2c6ea74e1",
            "ff60568d95814ca5bbedd1a8527c0a5a",
            "e7aa8e045bb44bc89d609f757bc632a4",
            "de5428f5dad64c51901ccef55fc0ef38",
            "d655d011b8ef4992bc193ac582c07ead",
            "35645e4101684ae0b660fe3bf94ba357",
            "13adb16b53b44491a8c4d6bdffa447fe",
            "15765081540d434280fadf2db7cad78c",
            "56dca4666247412b9808714ce4805fea",
            "23b25ce5aa0349f8b04bd2ecc7ccf53d",
            "bdbcb4e18d9b4a09810dbdf8d86918ab",
            "22e2fcc0358c43dcafbb20808eb9bd6a",
            "8217af31d5874e8e9f28134fd2b81803",
            "06e9d6d0bb4841e8b71b7330ab6e0555",
            "670513faf9124f5dbb52320659fa2685",
            "0e51603c5e1641dc9b8e1fcb24c8e7b0",
            "9495152d427d4d64b038d978418f84ef",
            "c2ba71fc40ee4a6f8d43586a1a9dde6a",
            "45a8bab3ff12426b866765869bd1d133",
            "1aabc9ad52fe48988266b82b171044af"
          ]
        },
        "id": "ApzJSW78lbd2",
        "outputId": "049aa7d8-7b08-47ac-af86-f578bd2cf89d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¥ Medical Chatbot with OpenAI\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "ğŸ’¡ Commands: 'exit' to quit, 'cost' for usage, 'cache' for history\n",
            "\n",
            "ğŸ’¬ **You**: What percentage of women experience complications that require hospitalization?\n",
            "ğŸ”„ Processing new query... \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ac41de3429c4381ae04debaa657c5b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ğŸ“š **RAG**: Less than 0.5% of women experience complications from abortions that require hospitalization.\n",
            "\n",
            "ğŸ“ **Sources**: Medical_book.pdf, p.26, Medical_book.pdf, p.354\n",
            "\n",
            "ğŸ’¬ **You**: In apgar testing, what is the score in most infants\n",
            "ğŸ”„ Processing new query... \n",
            "\n",
            "\n",
            "ğŸ§  **OPENAI**: In Apgar testing, most infants typically score between 7 and 10. Scores in this range indicate that the infant is in good health.\n",
            "\n",
            "ğŸ’¬ **You**: when the  CD4+ lymphocyte count falls below what number, he or  she is at risk for a variety of opportunistic infections?\n",
            "ğŸ”„ Processing new query... \n",
            "\n",
            "\n",
            "ğŸ§  **OPENAI**: When the CD4+ lymphocyte count falls below 200 cells/mmÂ³, an individual is at increased risk for a variety of opportunistic infections.\n",
            "\n",
            "ğŸ’¬ **You**: what is the percentage that PGL affects patients during latency\n",
            "ğŸ”„ Processing new query... \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23b25ce5aa0349f8b04bd2ecc7ccf53d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ğŸ“š **RAG**: PGL affects between 50-70% of patients during latency.\n",
            "\n",
            "ğŸ“ **Sources**: Medical_book.pdf, p.90, Medical_book.pdf, p.98\n",
            "\n",
            "ğŸ’¬ **You**: What percentage of women experience complications that require hospitalization?\n",
            "Using cached response! (No API cost)\n",
            "\n",
            "\n",
            "ğŸ“š **RAG**: Less than 0.5% of women experience complications from abortions that require hospitalization.\n",
            "\n",
            "ğŸ“ **Sources**: Medical_book.pdf, p.26, Medical_book.pdf, p.354\n",
            "\n",
            "ğŸ’¬ **You**: exit\n",
            "ğŸ‘‹ Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clear_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwOyZFdsvUSi",
        "outputId": "804e9d9e-a3b1-4483-e48e-eee31c37f8de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—‘ï¸ Cache cleared! All future questions will use fresh API calls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Gradio Web Interface (Optional)\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def chat_ui(user_input, history=[]):\n",
        "    \"\"\"Gradio chat interface function\"\"\"\n",
        "    if not user_input.strip():\n",
        "        return history, history\n",
        "\n",
        "    answer = cached_hybrid_query(user_input)\n",
        "    history = history + [(user_input, answer)]\n",
        "    return history, history\n",
        "\n",
        "def show_stats():\n",
        "    \"\"\"Show usage statistics\"\"\"\n",
        "    return f\"ğŸ“Š Questions: {len(cache)} | Cost: ${len(cache) * 0.005:.3f}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"Medical RAG Chatbot\") as demo:\n",
        "    gr.Markdown(\"# ğŸ¥ Medical Chatbot with OpenAI\")\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"Medical Assistant\", height=400)\n",
        "\n",
        "    with gr.Row():\n",
        "        user_input = gr.Textbox(placeholder=\"Ask your medical question...\", scale=4)\n",
        "        submit_btn = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
        "\n",
        "    with gr.Row():\n",
        "        clear_btn = gr.Button(\"Clear\")\n",
        "        stats_btn = gr.Button(\"Stats\")\n",
        "        usage_display = gr.Textbox(label=\"Usage\", interactive=False)\n",
        "\n",
        "    # Event handlers\n",
        "    submit_btn.click(chat_ui, [user_input, chatbot], [chatbot, chatbot]).then(lambda: \"\", outputs=[user_input])\n",
        "    user_input.submit(chat_ui, [user_input, chatbot], [chatbot, chatbot]).then(lambda: \"\", outputs=[user_input])\n",
        "    clear_btn.click(lambda: [], outputs=[chatbot])\n",
        "    stats_btn.click(show_stats, outputs=[usage_display])\n",
        "\n",
        "print(\"âœ… Gradio interface ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lvt8hsXlibj",
        "outputId": "5176d548-3eab-427c-c7f9-07da1b0aa522"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Gradio interface ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch Web Interface\n",
        "\n",
        "demo.launch(\n",
        "    share=True,          # Create public link\n",
        "    show_error=True,     # Show errors in interface\n",
        "    show_api=False       # Hide API docs\n",
        ")\n",
        "\n",
        "print(\"ğŸš€ Web interface launched!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "c-neZqz4nfN6",
        "outputId": "a011c6d5-21cf-45d0-d4ca-26e2d6b1ff1b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://43137af79f15cb34e1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://43137af79f15cb34e1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Web interface launched!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ybjFuKeEnldo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}