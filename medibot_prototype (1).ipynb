{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDtNFdNCs12l",
    "outputId": "853d30a9-f0ec-47b1-fa9c-785fde2ffef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.1.9)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
      "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.12/dist-packages (1.26.3)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.7)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.14.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.21.4)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.55.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (5.9.5)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.11.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-google-genai\n",
    "!pip install chromadb sentence-transformers PyMuPDF\n",
    "!pip install gradio python-dotenv psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIR9GxqFs9dE",
    "outputId": "952ab9d9-09f1-4238-c8e6-4b3cd4f5898f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "from datetime import datetime\n",
    "import psutil\n",
    "import socket\n",
    "import requests\n",
    "import signal\n",
    "import time\n",
    "import gc\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xi6N4aAktxSv",
    "outputId": "6b89746d-2015-44db-d483-be72df713449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration set up!\n",
      "📊 Chunk size: 1000 characters\n",
      "🔄 Chunk overlap: 200 characters\n",
      "🎯 Will retrieve top 5 results\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    # Embedding model (free, runs in Colab)\n",
    "    EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "    # Chunk settings\n",
    "    CHUNK_SIZE = 1000\n",
    "    CHUNK_OVERLAP = 200\n",
    "\n",
    "    # ChromaDB settings\n",
    "    CHROMA_PERSIST_DIR = \"./chroma_db\"\n",
    "    COLLECTION_NAME = \"medical_encyclopedia\"\n",
    "\n",
    "    # Gemini settings\n",
    "    GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "    # Retrieval settings\n",
    "    TOP_K_RESULTS = 5\n",
    "\n",
    "    # Network timeout settings\n",
    "    API_TIMEOUT = 30\n",
    "    MAX_RETRIES = 3\n",
    "\n",
    "print(\"✅ Configuration set up!\")\n",
    "print(f\"📊 Chunk size: {Config.CHUNK_SIZE} characters\")\n",
    "print(f\"🔄 Chunk overlap: {Config.CHUNK_OVERLAP} characters\")\n",
    "print(f\"🎯 Will retrieve top {Config.TOP_K_RESULTS} results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDY2twaBt_n4",
    "outputId": "60a3ff94-35f5-42dc-a9e5-aad921cc0dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Network cache cleared\n",
      "✅ Gemini API key loaded and configured\n",
      "🔑 Key status: AIzaSyCJ87...KEqqo\n"
     ]
    }
   ],
   "source": [
    "# Clear any cached network connections\n",
    "try:\n",
    "    requests.Session().close()\n",
    "    print(\"🧹 Network cache cleared\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Get Gemini API key from Colab secrets\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "\n",
    "    # Configure with better network settings\n",
    "    genai.configure(\n",
    "        api_key=GEMINI_API_KEY,\n",
    "        transport='rest'  # Force REST instead of gRPC for better stability\n",
    "    )\n",
    "    print(\"✅ Gemini API key loaded and configured\")\n",
    "    print(f\"🔑 Key status: {GEMINI_API_KEY[:10]}...{GEMINI_API_KEY[-5:]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Could not load GEMINI_API_KEY from secrets\")\n",
    "    print(\"Make sure you've added 'GEMINI_API_KEY' to your Colab secrets\")\n",
    "    print(\"Go to the key icon on the left sidebar > Add new secret\")\n",
    "    GEMINI_API_KEY = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSvc_DUJuEGl",
    "outputId": "fac21d57-882f-4734-9910-3f3bb1e99d97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 PDF processor initialized\n"
     ]
    }
   ],
   "source": [
    "class PDFProcessor:\n",
    "    def __init__(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=Config.CHUNK_SIZE,\n",
    "            chunk_overlap=Config.CHUNK_OVERLAP,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        )\n",
    "        print(\"📄 PDF processor initialized\")\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> List[Document]:\n",
    "        \"\"\"Extract text from PDF and create Document objects\"\"\"\n",
    "        documents = []\n",
    "\n",
    "        print(f\"📄 Processing PDF: {pdf_path}\")\n",
    "        doc = fitz.open(pdf_path)\n",
    "\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc[page_num]\n",
    "            text = page.get_text()\n",
    "\n",
    "            if text.strip():  # Only add non-empty pages\n",
    "                documents.append(Document(\n",
    "                    page_content=text,\n",
    "                    metadata={\n",
    "                        \"source\": pdf_path,\n",
    "                        \"page\": page_num + 1,\n",
    "                        \"total_pages\": len(doc)\n",
    "                    }\n",
    "                ))\n",
    "\n",
    "            # Show progress every 50 pages\n",
    "            if (page_num + 1) % 50 == 0:\n",
    "                print(f\"📖 Processed {page_num + 1}/{len(doc)} pages...\")\n",
    "\n",
    "        doc.close()\n",
    "        print(f\"✅ Extracted text from {len(documents)} pages\")\n",
    "        return documents\n",
    "\n",
    "    def chunk_documents(self, documents: List[Document]) -> List[Document]:\n",
    "        \"\"\"Split documents into smaller chunks\"\"\"\n",
    "        print(f\"🔪 Chunking {len(documents)} documents...\")\n",
    "        chunks = self.text_splitter.split_documents(documents)\n",
    "        print(f\"✅ Created {len(chunks)} chunks\")\n",
    "\n",
    "        # Show chunk statistics\n",
    "        chunk_lengths = [len(chunk.page_content) for chunk in chunks]\n",
    "        avg_length = sum(chunk_lengths) / len(chunk_lengths)\n",
    "        print(f\"📊 Average chunk length: {avg_length:.0f} characters\")\n",
    "        print(f\"📊 Min/Max chunk length: {min(chunk_lengths)}/{max(chunk_lengths)} characters\")\n",
    "\n",
    "        return chunks\n",
    "\n",
    "# Initialize PDF processor\n",
    "pdf_processor = PDFProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FzLlg4KvuIpo",
    "outputId": "7e3c1e50-0bb7-41ba-bdff-3887c745fe2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding model loaded\n",
      "📐 Embedding dimension: 384\n",
      "💾 ChromaDB initialized at: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    def __init__(self):\n",
    "        print(\"🤖 Loading embedding model...\")\n",
    "        self.model = SentenceTransformer(Config.EMBEDDING_MODEL)\n",
    "        print(\"✅ Embedding model loaded\")\n",
    "        print(f\"📐 Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "        # Initialize ChromaDB\n",
    "        self.client = chromadb.PersistentClient(path=Config.CHROMA_PERSIST_DIR)\n",
    "        print(f\"💾 ChromaDB initialized at: {Config.CHROMA_PERSIST_DIR}\")\n",
    "\n",
    "    def create_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Create embeddings for a list of texts\"\"\"\n",
    "        print(f\"🔄 Creating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"✅ Created embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings.tolist()\n",
    "\n",
    "    def setup_vector_store(self, chunks: List[Document]) -> chromadb.Collection:\n",
    "        \"\"\"Create or get ChromaDB collection and add documents\"\"\"\n",
    "\n",
    "        # Try to get existing collection\n",
    "        try:\n",
    "            collection = self.client.get_collection(Config.COLLECTION_NAME)\n",
    "            existing_count = collection.count()\n",
    "            print(f\"📚 Found existing collection with {existing_count} documents\")\n",
    "\n",
    "            # Ask if user wants to recreate\n",
    "            if existing_count > 0:\n",
    "                print(\"⚠️ Collection already exists with data.\")\n",
    "                print(\"Options: (1) Use existing, (2) Add to existing, (3) Recreate\")\n",
    "                choice = input(\"Enter choice (1/2/3): \").strip()\n",
    "\n",
    "                if choice == \"3\":\n",
    "                    self.client.delete_collection(Config.COLLECTION_NAME)\n",
    "                    collection = self.client.create_collection(Config.COLLECTION_NAME)\n",
    "                    print(\"🗑️ Deleted old collection, created new one\")\n",
    "                elif choice == \"1\":\n",
    "                    return collection\n",
    "                # choice == \"2\" continues to add documents\n",
    "\n",
    "        except Exception:\n",
    "            collection = self.client.create_collection(Config.COLLECTION_NAME)\n",
    "            print(\"📚 Created new collection\")\n",
    "\n",
    "        # Prepare data for ChromaDB\n",
    "        texts = [chunk.page_content for chunk in chunks]\n",
    "        metadatas = [chunk.metadata for chunk in chunks]\n",
    "\n",
    "        # Generate unique IDs based on existing count\n",
    "        existing_count = collection.count()\n",
    "        ids = [f\"chunk_{existing_count + i}\" for i in range(len(chunks))]\n",
    "\n",
    "        print(f\"🔢 Generating {len(ids)} unique document IDs...\")\n",
    "\n",
    "        # Create embeddings\n",
    "        embeddings = self.create_embeddings(texts)\n",
    "\n",
    "        # Add to collection in batches (ChromaDB has limits)\n",
    "        batch_size = 100\n",
    "        total_batches = (len(texts) - 1) // batch_size + 1\n",
    "\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_end = min(i + batch_size, len(texts))\n",
    "            batch_num = i // batch_size + 1\n",
    "\n",
    "            print(f\"📥 Adding batch {batch_num}/{total_batches} ({batch_end - i} documents)...\")\n",
    "\n",
    "            collection.add(\n",
    "                documents=texts[i:batch_end],\n",
    "                embeddings=embeddings[i:batch_end],\n",
    "                metadatas=metadatas[i:batch_end],\n",
    "                ids=ids[i:batch_end]\n",
    "            )\n",
    "\n",
    "        final_count = collection.count()\n",
    "        print(f\"✅ Vector store ready with {final_count} total documents\")\n",
    "        return collection\n",
    "\n",
    "# Initialize embedding manager\n",
    "embedding_manager = EmbeddingManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "tcdvS6PwuMtv",
    "outputId": "74eafc2f-7cf8-4c7e-f687-765e129c2dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Please upload your medical encyclopedia PDF:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-a0cbc4c1-3c1a-434a-8d06-246c68de6e63\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-a0cbc4c1-3c1a-434a-8d06-246c68de6e63\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Medical_book.pdf to Medical_book (1).pdf\n",
      "📄 Uploaded file: Medical_book (1).pdf\n",
      "📊 File size: 15.4 MB\n",
      "📄 Processing PDF: Medical_book (1).pdf\n",
      "📖 Processed 50/637 pages...\n",
      "📖 Processed 100/637 pages...\n",
      "📖 Processed 150/637 pages...\n",
      "📖 Processed 200/637 pages...\n",
      "📖 Processed 250/637 pages...\n",
      "📖 Processed 300/637 pages...\n",
      "📖 Processed 350/637 pages...\n",
      "📖 Processed 400/637 pages...\n",
      "📖 Processed 450/637 pages...\n",
      "📖 Processed 500/637 pages...\n",
      "📖 Processed 550/637 pages...\n",
      "📖 Processed 600/637 pages...\n",
      "✅ Extracted text from 636 pages\n",
      "🔪 Chunking 636 documents...\n",
      "✅ Created 3391 chunks\n",
      "📊 Average chunk length: 905 characters\n",
      "📊 Min/Max chunk length: 48/1000 characters\n",
      "📋 Processing Summary:\n",
      "   📄 Total pages: 636\n",
      "   🔪 Total chunks: 3391\n",
      "   💽 Estimated storage: ~5.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Upload your medical encyclopedia PDF\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"📁 Please upload your medical encyclopedia PDF:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded file path\n",
    "pdf_path = list(uploaded.keys())[0]\n",
    "print(f\"📄 Uploaded file: {pdf_path}\")\n",
    "\n",
    "# Check file size\n",
    "file_size = os.path.getsize(pdf_path) / (1024 * 1024)  # MB\n",
    "print(f\"📊 File size: {file_size:.1f} MB\")\n",
    "\n",
    "# Extract text from PDF\n",
    "documents = pdf_processor.extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Create chunks\n",
    "chunks = pdf_processor.chunk_documents(documents)\n",
    "\n",
    "print(f\"📋 Processing Summary:\")\n",
    "print(f\"   📄 Total pages: {len(documents)}\")\n",
    "print(f\"   🔪 Total chunks: {len(chunks)}\")\n",
    "print(f\"   💽 Estimated storage: ~{len(chunks) * 384 * 4 / 1024 / 1024:.1f} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vvdP_JOiLkc",
    "outputId": "eeac9705-01c2-4200-a456-b9dc076f53a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Creating vector store...\n",
      "This may take a few minutes depending on document size...\n",
      "📚 Found existing collection with 3391 documents\n",
      "⚠️ Collection already exists with data.\n",
      "Options: (1) Use existing, (2) Add to existing, (3) Recreate\n",
      "Enter choice (1/2/3): 1\n",
      "✅ Vector store creation complete!\n",
      "📊 Final statistics:\n",
      "   💾 Total documents in database: 3391\n",
      "   🔍 Ready for similarity search!\n"
     ]
    }
   ],
   "source": [
    "# Create Vector Store\n",
    "\n",
    "print(\"🚀 Creating vector store...\")\n",
    "print(\"This may take a few minutes depending on document size...\")\n",
    "\n",
    "# Create the vector store\n",
    "collection = embedding_manager.setup_vector_store(chunks)\n",
    "\n",
    "print(\"✅ Vector store creation complete!\")\n",
    "print(f\"📊 Final statistics:\")\n",
    "print(f\"   💾 Total documents in database: {collection.count()}\")\n",
    "print(f\"   🔍 Ready for similarity search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "l0yAbBmkicyV",
    "outputId": "fc849784-b707-46d2-a674-b7924be73131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini LLM tested and working\n"
     ]
    }
   ],
   "source": [
    "# Enhanced RAG System Class\n",
    "\n",
    "class MedicalRAG:\n",
    "    def __init__(self, collection: chromadb.Collection, embedding_manager: EmbeddingManager):\n",
    "        self.collection = collection\n",
    "        self.embedding_manager = embedding_manager\n",
    "        self.gemini_available = False\n",
    "\n",
    "        if GEMINI_API_KEY:\n",
    "            try:\n",
    "                self.llm = genai.GenerativeModel(Config.GEMINI_MODEL)\n",
    "                # Test if Gemini is working\n",
    "                self._test_gemini()\n",
    "            except:\n",
    "                self.llm = None\n",
    "                print(\"⚠️ Gemini initialization failed - using retrieval-only mode\")\n",
    "        else:\n",
    "            self.llm = None\n",
    "            print(\"⚠️ No Gemini API key - retrieval-only mode\")\n",
    "\n",
    "    def _test_gemini(self):\n",
    "        \"\"\"Test if Gemini API is working\"\"\"\n",
    "        try:\n",
    "            def timeout_handler(signum, frame):\n",
    "                raise TimeoutError(\"Gemini test timed out\")\n",
    "\n",
    "            signal.signal(signal.SIGALRM, timeout_handler)\n",
    "            signal.alarm(5)  # 5 second timeout for test\n",
    "\n",
    "            response = self.llm.generate_content(\n",
    "                \"Hi\",\n",
    "                generation_config=genai.types.GenerationConfig(max_output_tokens=5)\n",
    "            )\n",
    "            signal.alarm(0)  # Cancel timeout\n",
    "\n",
    "            self.gemini_available = True\n",
    "            print(\"✅ Gemini LLM tested and working\")\n",
    "\n",
    "        except Exception as e:\n",
    "            signal.alarm(0)  # Cancel timeout\n",
    "            self.gemini_available = False\n",
    "            print(f\"⚠️ Gemini test failed: {str(e)[:100]}...\")\n",
    "            print(\"📚 Using retrieval-only mode (still very useful!)\")\n",
    "\n",
    "    def retrieve_documents(self, query: str, top_k: int = Config.TOP_K_RESULTS) -> List[Dict]:\n",
    "        \"\"\"Retrieve relevant documents for a query\"\"\"\n",
    "        print(f\"🔍 Searching for: '{query}'\")\n",
    "\n",
    "        # Create query embedding\n",
    "        query_embedding = self.embedding_manager.create_embeddings([query])[0]\n",
    "\n",
    "        # Search in ChromaDB\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=top_k,\n",
    "            include=['documents', 'metadatas', 'distances']\n",
    "        )\n",
    "\n",
    "        # Format results\n",
    "        retrieved_docs = []\n",
    "        for i in range(len(results['documents'][0])):\n",
    "            similarity_score = 1 - results['distances'][0][i]  # Convert distance to similarity\n",
    "            retrieved_docs.append({\n",
    "                'content': results['documents'][0][i],\n",
    "                'metadata': results['metadatas'][0][i],\n",
    "                'score': similarity_score\n",
    "            })\n",
    "\n",
    "        print(f\"✅ Retrieved {len(retrieved_docs)} relevant documents\")\n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            page = doc['metadata'].get('page', '?')\n",
    "            score = doc['score']\n",
    "            print(f\"   {i}. Page {page} (similarity: {score:.3f})\")\n",
    "\n",
    "        return retrieved_docs\n",
    "\n",
    "    def generate_answer(self, query: str, retrieved_docs: List[Dict]) -> str:\n",
    "        \"\"\"Generate answer using Gemini and retrieved documents\"\"\"\n",
    "        if not self.gemini_available:\n",
    "            return self._format_retrieval_answer(query, retrieved_docs)\n",
    "\n",
    "        # Prepare context from retrieved documents - limit size to prevent timeouts\n",
    "        context_parts = []\n",
    "        total_chars = 0\n",
    "        max_context_chars = 3000  # Limit context size\n",
    "\n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            page_info = f\"Page {doc['metadata'].get('page', '?')}\"\n",
    "            content = doc['content']\n",
    "\n",
    "            # Limit individual document size\n",
    "            if len(content) > 800:\n",
    "                content = content[:800] + \"...\"\n",
    "\n",
    "            doc_text = f\"[Source {i} - {page_info}]\\n{content}\\n\"\n",
    "\n",
    "            if total_chars + len(doc_text) > max_context_chars:\n",
    "                break\n",
    "\n",
    "            context_parts.append(doc_text)\n",
    "            total_chars += len(doc_text)\n",
    "\n",
    "        context = \"\\n\".join(context_parts)\n",
    "\n",
    "        # Create medical-focused prompt\n",
    "        prompt = f\"\"\"You are a medical AI assistant. Answer based ONLY on the provided medical encyclopedia context.\n",
    "\n",
    "GUIDELINES:\n",
    "- Use only information from the provided context\n",
    "- Include source references (e.g., \"According to Source 1, Page X...\")\n",
    "- Be precise and factual\n",
    "- Always remind users to consult healthcare professionals\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION: {query}\n",
    "\n",
    "ANSWER:\"\"\"\n",
    "\n",
    "        try:\n",
    "            def timeout_handler(signum, frame):\n",
    "                raise TimeoutError(\"Generation timed out\")\n",
    "\n",
    "            signal.signal(signal.SIGALRM, timeout_handler)\n",
    "            signal.alarm(Config.API_TIMEOUT)  # 30 second timeout\n",
    "\n",
    "            response = self.llm.generate_content(\n",
    "                prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    max_output_tokens=500,  # Limit output size\n",
    "                    temperature=0.1\n",
    "                )\n",
    "            )\n",
    "            signal.alarm(0)  # Cancel timeout\n",
    "            return response.text\n",
    "\n",
    "        except Exception as e:\n",
    "            signal.alarm(0)  # Cancel timeout\n",
    "            print(f\"❌ Gemini generation failed: {str(e)[:100]}...\")\n",
    "            print(\"📚 Falling back to retrieval-only answer\")\n",
    "            return self._format_retrieval_answer(query, retrieved_docs)\n",
    "\n",
    "    def _format_retrieval_answer(self, query: str, retrieved_docs: List[Dict]) -> str:\n",
    "        \"\"\"Format a professional answer using only retrieval results\"\"\"\n",
    "        answer_parts = []\n",
    "        answer_parts.append(f\"📚 **Medical Encyclopedia Results for: {query}**\\n\")\n",
    "\n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            page = doc['metadata'].get('page', '?')\n",
    "            score = doc['score']\n",
    "            content = doc['content']\n",
    "\n",
    "            answer_parts.append(f\"**📄 Source {i} - Page {page} (Relevance: {score:.1%})**\")\n",
    "\n",
    "            # Clean and format content\n",
    "            paragraphs = content.split('\\n\\n')\n",
    "            for para in paragraphs[:2]:  # Show first 2 paragraphs\n",
    "                if para.strip():\n",
    "                    answer_parts.append(para.strip())\n",
    "\n",
    "            if len(paragraphs) > 2:\n",
    "                answer_parts.append(\"*[Additional content available...]*\")\n",
    "\n",
    "            answer_parts.append(\"\")  # Empty line between sources\n",
    "\n",
    "        answer_parts.append(\"⚠️ **Medical Disclaimer:** This information is for educational purposes only. Always consult qualified healthcare professionals for medical advice, diagnosis, or treatment.\")\n",
    "\n",
    "        return \"\\n\".join(answer_parts)\n",
    "\n",
    "    def ask(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Main RAG function: retrieve + generate\"\"\"\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        # Retrieve relevant documents\n",
    "        retrieved_docs = self.retrieve_documents(query)\n",
    "\n",
    "        # Generate answer\n",
    "        answer = self.generate_answer(query, retrieved_docs)\n",
    "\n",
    "        end_time = datetime.now()\n",
    "        processing_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "        return {\n",
    "            'query': query,\n",
    "            'answer': answer,\n",
    "            'sources': retrieved_docs,\n",
    "            'timestamp': start_time.isoformat(),\n",
    "            'processing_time': processing_time,\n",
    "            'gemini_used': self.gemini_available\n",
    "        }\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = MedicalRAG(collection, embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431,
     "referenced_widgets": [
      "400d6af7defd4447b6efc92490a4119e",
      "8b0f5a5d307f4f10a78f30916a686c11",
      "f4bffd58580f4b4180dac11b8acab873",
      "3efe4db32f024510909968ef8512ed17",
      "ba9fc0c7a76346b1bb206cb4d39aaf83",
      "082f5c9bce7740a584565e146f99f455",
      "b46e5e63fd7647209764f46fa70821f1",
      "6bdf56cbe2164d53815e4158f5a19561",
      "3e4f88cda23d40179e3866b5f0e2fb90",
      "0f93d71833284076916604df6104d793",
      "a041661d4e0c4fa789960181b1790171"
     ]
    },
    "id": "fK9z8wkcuvJ9",
    "outputId": "f4ec6b9f-dd3a-4c37-b696-2b0cd5d10e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 MEDICAL RAG SYSTEM DIAGNOSTIC\n",
      "==================================================\n",
      "⏰ Current time: 2025-08-20 18:51:19.731279\n",
      "💾 Memory usage: 19.0%\n",
      "🔢 Documents in database: 3,391\n",
      "✅ RAG system type: <class '__main__.MedicalRAG'>\n",
      "🤖 Gemini available: Yes\n",
      "🔑 API key exists: Yes\n",
      "\n",
      "🔍 Testing document retrieval...\n",
      "🔍 Searching for: 'test'\n",
      "🔄 Creating embeddings for 1 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400d6af7defd4447b6efc92490a4119e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created embeddings with shape: (1, 384)\n",
      "✅ Retrieved 1 relevant documents\n",
      "   1. Page 479 (similarity: -0.200)\n",
      "✅ Retrieval works - found page 479\n",
      "\n",
      "🌐 Testing network connectivity...\n",
      "✅ Network connectivity good\n",
      "\n",
      "🎉 System diagnostic complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def system_diagnostic():\n",
    "    \"\"\"Run comprehensive system diagnostic\"\"\"\n",
    "    print(\"🔧 MEDICAL RAG SYSTEM DIAGNOSTIC\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Basic system check\n",
    "    try:\n",
    "        print(f\"⏰ Current time: {datetime.now()}\")\n",
    "        print(f\"💾 Memory usage: {psutil.virtual_memory().percent:.1f}%\")\n",
    "        print(f\"🔢 Documents in database: {collection.count():,}\")\n",
    "        print(f\"✅ RAG system type: {type(rag_system)}\")\n",
    "        print(f\"🤖 Gemini available: {'Yes' if rag_system.gemini_available else 'No'}\")\n",
    "        print(f\"🔑 API key exists: {'Yes' if GEMINI_API_KEY else 'No'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Basic diagnostic failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Test retrieval\n",
    "    try:\n",
    "        print(f\"\\n🔍 Testing document retrieval...\")\n",
    "        test_docs = rag_system.retrieve_documents(\"test\", 1)\n",
    "        print(f\"✅ Retrieval works - found page {test_docs[0]['metadata']['page']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Retrieval test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Test network connectivity\n",
    "    try:\n",
    "        print(f\"\\n🌐 Testing network connectivity...\")\n",
    "        socket.create_connection((\"8.8.8.8\", 53), timeout=5)\n",
    "        print(\"✅ Network connectivity good\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Network issue: {e}\")\n",
    "\n",
    "    print(f\"\\n🎉 System diagnostic complete!\")\n",
    "    return True\n",
    "\n",
    "# Run diagnostic\n",
    "system_diagnostic()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhAab4ewsWN7",
    "outputId": "b480d8f0-a043-4f91-b450-05ffd2acc23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡 **Available Functions:**\n",
      "• medical_search('your question') - Detailed search results\n",
      "• quick_query('your question') - Quick answer with AI\n"
     ]
    }
   ],
   "source": [
    "# Medical Search Functions\n",
    "\n",
    "def medical_search(question: str, num_results: int = 5):\n",
    "    \"\"\"Professional medical search function\"\"\"\n",
    "    print(\"🏥 MEDICAL ENCYCLOPEDIA SEARCH\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Get search results\n",
    "    docs = rag_system.retrieve_documents(question, num_results)\n",
    "\n",
    "    print(f\"\\n📚 EVIDENCE FROM MEDICAL ENCYCLOPEDIA:\")\n",
    "    print(f\"Found {len(docs)} relevant sections from your 637-page encyclopedia\\n\")\n",
    "\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        page = doc['metadata'].get('page', '?')\n",
    "        score = doc['score']\n",
    "\n",
    "        print(f\"📄 **SOURCE {i}: PAGE {page}**\")\n",
    "        print(f\"🎯 Relevance: {score:.1%}\")\n",
    "        print(\"─\" * 50)\n",
    "\n",
    "        # Format content nicely\n",
    "        content = doc['content'].strip()\n",
    "        paragraphs = content.split('\\n\\n')\n",
    "\n",
    "        for j, para in enumerate(paragraphs):\n",
    "            if para.strip():\n",
    "                print(para.strip())\n",
    "                if j < len(paragraphs) - 1:  # Add spacing between paragraphs\n",
    "                    print()\n",
    "\n",
    "        print(\"─\" * 50)\n",
    "        print()\n",
    "\n",
    "    print(\"⚠️ **Medical Disclaimer:** This information is for educational purposes only.\")\n",
    "    print(\"Always consult qualified healthcare professionals for medical advice.\\n\")\n",
    "\n",
    "    return docs\n",
    "\n",
    "def quick_query(question: str):\n",
    "    \"\"\"Quick query with both search results and AI answer\"\"\"\n",
    "    print(f\"❓ **Question:** {question}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    result = rag_system.ask(question)\n",
    "\n",
    "    print(\"🤖 **ANSWER:**\")\n",
    "    print(result['answer'])\n",
    "    print(f\"\\n⏱️ Processing time: {result['processing_time']:.2f} seconds\")\n",
    "    print(f\"🔧 Method: {'AI + Retrieval' if result['gemini_used'] else 'Retrieval Only'}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example searches you can run:\n",
    "print(\"💡 **Available Functions:**\")\n",
    "print(\"• medical_search('your question') - Detailed search results\")\n",
    "print(\"• quick_query('your question') - Quick answer with AI\")\n",
    "  # print(\"\\n🧪 **Try these examples:**\")\n",
    "  # print(\"• medical_search('diabetes symptoms')\")\n",
    "  # print(\"• quick_query('How is hypertension treated?')\")\n",
    "  # print(\"• medical_search('heart disease causes')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6c38ba7200f9451c8f0f695dc6c681e5",
      "100ec11a468e477989506fbd7aaf87e8",
      "a8d12643eccd49a39cd0d8d8778bfa5e",
      "74a6b3f7350e47d78b53cc15d9e87319",
      "338118cb60e648168ca448ef4a368333",
      "53c62857df9d4ece877062019a0a7d2b",
      "ee22803772fb457bbf20717af66e4edf",
      "029b8354b87748258297a8cf51a83609",
      "58774e82f9cd4eb78ae9c0b2e4df6406",
      "b41fbdb250d443b2afdd2d174ce1acdc",
      "51897d56a20642bda1305d966ddab940",
      "48056d6751724a4c9c169a8387d6bae0",
      "122c549bc9c1433cace505699371ed0b",
      "592f1eebeaa64b388ebc346d3462d9e1",
      "1122e31600dc46009167295e58018c64",
      "39d69c6951d648b68b4e5ef1ebcd8f90",
      "86b2322ac5be4efba06577176444005a",
      "f5da8ab0500141ef857541987dba5be4",
      "c7553781814a494b803d77b9f8b06c1b",
      "53096f03ad21470880d73211bddcef72",
      "f6c196ef625f40749bcd0c9b1e40cc15",
      "d2c316a232194a89bfee5bbd2e7fdf02",
      "470b535359ac43dd8608adf685815776",
      "f3eafeaf5bd24677973e19210d116a6c",
      "76a80d51779a4ba6bebbddc86d809029",
      "d4558a75b36a48a88374a06906fa7645",
      "db2b9eab0d8746e3aa261b7196c197f5",
      "a1ac108acbfb482dbfc98d8392fd764e",
      "9e98fee7ca3349cabdd89024b642bcca",
      "3e9d25d382224894a828312177bc44c5",
      "ffac96603b274cf2ac7cc59ce756a2d3",
      "6b874a5a9bc2457a83ab1b3d6c0ed505",
      "46d6c9acb5284c259c13d483a9da96cb"
     ]
    },
    "id": "-Sns9liDyZRH",
    "outputId": "de2d21e2-d784-46a3-d51c-f81ac9ad3922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏥 MEDICAL ENCYCLOPEDIA SEARCH\n",
      "============================================================\n",
      "Question: heart attack symptoms\n",
      "============================================================\n",
      "🔍 Searching for: 'heart attack symptoms'\n",
      "🔄 Creating embeddings for 1 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c38ba7200f9451c8f0f695dc6c681e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created embeddings with shape: (1, 384)\n",
      "✅ Retrieved 5 relevant documents\n",
      "   1. Page 209 (similarity: 0.200)\n",
      "   2. Page 208 (similarity: 0.123)\n",
      "   3. Page 342 (similarity: 0.044)\n",
      "   4. Page 343 (similarity: 0.034)\n",
      "   5. Page 421 (similarity: 0.015)\n",
      "\n",
      "📚 EVIDENCE FROM MEDICAL ENCYCLOPEDIA:\n",
      "Found 5 relevant sections from your 637-page encyclopedia\n",
      "\n",
      "📄 **SOURCE 1: PAGE 209**\n",
      "🎯 Relevance: 20.0%\n",
      "──────────────────────────────────────────────────\n",
      "nary artery muscle spasm of insufficient duration or\n",
      "intensity to cause an actual heart attack.\n",
      "Causes and symptoms\n",
      "Angina causes a pressing pain or sensation of heavi-\n",
      "ness, usually in the chest area under the breast bone (ster-\n",
      "num). It occasionally is experienced in the shoulder, arm,\n",
      "neck, or jaw regions. Because episodes of angina occur\n",
      "when the heart’s need for oxygen increases beyond the\n",
      "oxygen available from the blood nourishing the heart, the\n",
      "condition is often precipitated by physical exertion. In\n",
      "most cases, the symptoms are relieved within a few min-\n",
      "utes by resting or by taking prescribed angina medica-\n",
      "tions. Emotional stress, extreme temperatures, heavy\n",
      "meals, cigarette smoking, and alcohol can also cause or\n",
      "contribute to an episode of angina.\n",
      "Diagnosis\n",
      "Physicians can usually diagnose angina based on the\n",
      "patient’s symptoms and the precipitating factors. Howev-\n",
      "er, other diagnostic testing is often required to confirm or\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 2: PAGE 208**\n",
      "🎯 Relevance: 12.3%\n",
      "──────────────────────────────────────────────────\n",
      "to the heart muscle. An episode of angina is not an actual\n",
      "heart attack, but rather pain that results from the heart\n",
      "muscle temporarily receiving too little blood. This tem-\n",
      "porary condition may be the result of demanding activi-\n",
      "ties such as exercise and does not necessarily indicate\n",
      "that the heart muscle is experiencing permanent damage.\n",
      "In fact, episodes of angina seldom cause permanent dam-\n",
      "age to heart muscle.\n",
      "Angina can be subdivided further into two cate-\n",
      "gories: angina of effort and variant angina.\n",
      "Angina of effort\n",
      "Angina of effort is a common disorder caused by the\n",
      "narrowing of the arteries (atherosclerosis) that supply\n",
      "oxygen-rich blood to the heart muscle. In the case of\n",
      "angina of effort, the heart (coronary) arteries can provide\n",
      "the heart muscle (myocardium) adequate blood during\n",
      "rest but not during periods of exercise, stress, or excite-\n",
      "ment—any of which may precipitate pain. The pain is\n",
      "relieved by resting or by administering nitroglycerin, a\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 3: PAGE 342**\n",
      "🎯 Relevance: 4.4%\n",
      "──────────────────────────────────────────────────\n",
      "the main cause of this condition in both men and women.\n",
      "Aortic valve insufficiency can remain unnoticed for\n",
      "10 to 15 years. In cases of severe insufficiency a person\n",
      "may notice a variety of symptoms, including an uncom-\n",
      "fortable pounding of the heart when lying down, a very\n",
      "rapid or hard heart beat (palpitations), shortness of\n",
      "breath, chest pain, and if untreated for very long times,\n",
      "swelling of the liver, ankles, and belly.\n",
      "Diagnosis\n",
      "A poorly functioning or insufficient aortic valve can\n",
      "be identified when a doctor listens to the heart during a\n",
      "physical examination. A chest x ray, an electrocardio-\n",
      "gram (ECG, an electrical printout of the heart beats), as\n",
      "well as an echocardiogram (a test that uses sound waves\n",
      "to create an image of the heart and its valves), can further\n",
      "evaluate or confirm the condition.\n",
      "Treatment\n",
      "Aortic insufficiency is usually corrected by having\n",
      "the defective valve surgically replaced. However, such an\n",
      "operation is done in severe cases. Before the condition\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 4: PAGE 343**\n",
      "🎯 Relevance: 3.4%\n",
      "──────────────────────────────────────────────────\n",
      "may form on the valve with aging, causing the valve to\n",
      "become stiff and narrow. Stenosis can also occur as a\n",
      "result of rheumatic fever. Mild aortic stenosis may pro-\n",
      "duce no symptoms at all. The most common symptoms,\n",
      "depending on the severity of the disease, are chest pain,\n",
      "blackouts, and difficulty breathing.\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2\n",
      "329\n",
      "Aortic valve stenosis\n",
      "Normal\n",
      "blood flow\n",
      "Diseased valve\n",
      "Blood backflow\n",
      "A human heart with a diseased valve that doesn’t open and\n",
      "close properly, allowing blood to backflow to the heart.\n",
      "(Illustration by Argosy, Inc.)\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 5: PAGE 421**\n",
      "🎯 Relevance: 1.5%\n",
      "──────────────────────────────────────────────────\n",
      "tis), chest trauma or surgery, pulmonary disease, and cer-\n",
      "tain medications. Atrial fibrillation is more common in\n",
      "older people; about 10% of people over the age of 75\n",
      "have it. Atrial flutter and fibrillation usually occur in peo-\n",
      "ple with hypertensive or coronary heart disease and other\n",
      "types of heart disorders.\n",
      "Causes and symptoms\n",
      "In most cases, the cause of atrial fibrillation and flut-\n",
      "ter can be found, but often it cannot. Causes of these\n",
      "heart beat abnormalities include:\n",
      "• many types of heart disease\n",
      "• stress and anxiety\n",
      "• caffeine\n",
      "• alcohol\n",
      "• tobacco\n",
      "• diet pills\n",
      "• some prescription and over-the-counter medications\n",
      "• open heart surgery\n",
      "Symptoms, when present, include:\n",
      "• a fluttering feeling in the chest\n",
      "• a pulse that feels like the heart is skipping, racing, jump-\n",
      "ing, or is irregular\n",
      "• low energy\n",
      "• a faint or dizzy feeling\n",
      "• pressure or discomfort in the chest\n",
      "• shortness of breath\n",
      "• anxiety.\n",
      "Diagnosis\n",
      "A doctor can sometimes hear these arrhythmias\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "⚠️ **Medical Disclaimer:** This information is for educational purposes only.\n",
      "Always consult qualified healthcare professionals for medical advice.\n",
      "\n",
      "🏥 MEDICAL ENCYCLOPEDIA SEARCH\n",
      "============================================================\n",
      "Question: thyroid disorders\n",
      "============================================================\n",
      "🔍 Searching for: 'thyroid disorders'\n",
      "🔄 Creating embeddings for 1 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48056d6751724a4c9c169a8387d6bae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created embeddings with shape: (1, 384)\n",
      "✅ Retrieved 5 relevant documents\n",
      "   1. Page 436 (similarity: 0.085)\n",
      "   2. Page 437 (similarity: -0.030)\n",
      "   3. Page 337 (similarity: -0.032)\n",
      "   4. Page 75 (similarity: -0.034)\n",
      "   5. Page 402 (similarity: -0.062)\n",
      "\n",
      "📚 EVIDENCE FROM MEDICAL ENCYCLOPEDIA:\n",
      "Found 5 relevant sections from your 637-page encyclopedia\n",
      "\n",
      "📄 **SOURCE 1: PAGE 436**\n",
      "🎯 Relevance: 8.5%\n",
      "──────────────────────────────────────────────────\n",
      "tem attacks and destroys the tissues that line bone joints\n",
      "and cartilage. The disease occurs throughout the body,\n",
      "although some joints may be more affected than others.\n",
      "• Goodpasture’s syndrome. Occurs when antibodies are\n",
      "deposited in the membranes of both the lung and kid-\n",
      "neys, causing both inflammation of kidney glomerulus\n",
      "(glomerulonephritis) and lung bleeding. It is typically\n",
      "a disease of young males.\n",
      "• Grave’s disease. Caused by an antibody that binds to\n",
      "specific cells in the thyroid gland, causing them to\n",
      "make excessive amounts of thyroid hormone.\n",
      "• Hashimoto’s thyroiditis. Caused by an antibody that\n",
      "binds to cells in the thyroid gland. Unlike in Grave’s\n",
      "disease, however, this antibody’s action results in less\n",
      "thyroid hormone being made.\n",
      "• Pemphigus vulgaris. A group of autoimmune disorders\n",
      "that affect the skin.\n",
      "• Myasthenia gravis. A condition in which the immune\n",
      "system attacks a receptor on the surface of muscle cells,\n",
      "preventing the muscle from receiving nerve impulses\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 2: PAGE 437**\n",
      "🎯 Relevance: -3.0%\n",
      "──────────────────────────────────────────────────\n",
      "ly the characteristic “swan’s neck” curling of the fingers.\n",
      "• Goodpasture’s syndrome. Symptoms are similar to that\n",
      "of iron deficiency anemia, including fatigue and pal-\n",
      "lor. Symptoms involving the lungs may range from a\n",
      "cough that produces bloody sputum to outright hemor-\n",
      "rhaging. Symptoms involving the urinary system\n",
      "include blood in the urine and/or swelling.\n",
      "• Grave’s disease. This disease is characterized by an\n",
      "enlarged thyroid gland, weight loss without loss of\n",
      "appetite, sweating, heart palpitations, nervousness,\n",
      "and an inability to tolerate heat.\n",
      "• Hashimoto’s thyroiditis. This disorder generally dis-\n",
      "plays no symptoms.\n",
      "• Pemphigus vulgaris. This disease is characterized by\n",
      "blisters and deep lesions on the skin.\n",
      "• Myasthenia gravis. Characterized by fatigue and mus-\n",
      "cle weakness that at first may be confined to certain\n",
      "muscle groups, but then may progress to the point of\n",
      "paralysis. Myasthenia gravis patients often have expres-\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 3: PAGE 337**\n",
      "🎯 Relevance: -3.2%\n",
      "──────────────────────────────────────────────────\n",
      "thyroid function are also common\n",
      "Diagnostic testing for anxiety\n",
      "There are no laboratory tests that can diagnose anxi-\n",
      "ety, although the doctor may order some specific tests to\n",
      "rule out disease conditions. Although there is no psychi-\n",
      "atric test that can provide definite diagnoses of anxiety dis-\n",
      "orders, there are several short-answer interviews or symp-\n",
      "tom inventories that doctors can use to evaluate the inten-\n",
      "sity of a patient’s anxiety and some of its associated fea-\n",
      "tures. These measures include the Hamilton Anxiety Scale\n",
      "and the Anxiety Disorders Interview Schedule (ADIS).\n",
      "Treatment\n",
      "For relatively mild anxiety disorders, psychotherapy\n",
      "alone may suffice. In general, doctors prefer to use a com-\n",
      "bination of medications and psychotherapy with more\n",
      "severely anxious patients. Most patients respond better to\n",
      "a combination of treatment methods than to either med-\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2\n",
      "323\n",
      "Anxiety disorders\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 4: PAGE 75**\n",
      "🎯 Relevance: -3.4%\n",
      "──────────────────────────────────────────────────\n",
      "thyroid from taking up radioactive iodine and interfering\n",
      "with the scan.\n",
      "Aftercare\n",
      "The patient should not feel any adverse effects of the\n",
      "test and can resume normal activity immediately. Follow-\n",
      "up tests that might be ordered include a nuclear scan of\n",
      "the bones or kidney, a computed tomography scan (CT)\n",
      "of the adrenals, or an ultrasound of the pelvic area.\n",
      "Risks\n",
      "The main risk associated with this test is to the fetus\n",
      "of a pregnant woman.\n",
      "KEY TERMS\n",
      "Adrenal cortex—The outer tissue of the adrenal\n",
      "gland. It produces a group of chemically related\n",
      "hormones called corticosteroids that control min-\n",
      "eral and water balance in the body and include\n",
      "aldosterone and cortisol.\n",
      "Adrenal medulla—The inner tissue of the adrenal\n",
      "gland. It produces the hormones adrenaline and\n",
      "noradrenaline.\n",
      "Lugol’s solution—A strong iodine solution.\n",
      "Normal results\n",
      "Normal results will show no unusual areas of hor-\n",
      "mone secretion and no tumors.\n",
      "Abnormal results\n",
      "Abnormal results will show evidence of a tumor\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 5: PAGE 402**\n",
      "🎯 Relevance: -6.2%\n",
      "──────────────────────────────────────────────────\n",
      "hood that progressively destroys part of the motor control\n",
      "area of the brain, leading to a lack of balance and coordina-\n",
      "tion. A-T also affects the immune system and increases the\n",
      "risk of leukemia and lymphoma in affected individuals.\n",
      "Description\n",
      "The disorder first appeared in the medical literature in\n",
      "the mid-1920s, but was not named specifically until 1957.\n",
      "The name is a combination of two recognized abnormali-\n",
      "ties: ataxia (lack of muscle control) and telangiectasia\n",
      "(abnormal dilatation of capillary vessels that often result in\n",
      "tumors and red skin lesions). However, A-T involves more\n",
      "than just the sum of these two findings. Other associated\n",
      "A-T problems include immune system deficiencies,\n",
      "extreme sensitivity to radiation, and blood cancers.\n",
      "Medical researchers initially suspected that multiple\n",
      "genes (the units responsible for inherited features) were\n",
      "involved. However, in 1995, mutations in a single large\n",
      "gene were identified as causing A-T. Researchers named\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "⚠️ **Medical Disclaimer:** This information is for educational purposes only.\n",
      "Always consult qualified healthcare professionals for medical advice.\n",
      "\n",
      "🏥 MEDICAL ENCYCLOPEDIA SEARCH\n",
      "============================================================\n",
      "Question: fatty liver treatment\n",
      "============================================================\n",
      "🔍 Searching for: 'fatty liver treatment'\n",
      "🔄 Creating embeddings for 1 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470b535359ac43dd8608adf685815776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created embeddings with shape: (1, 384)\n",
      "✅ Retrieved 5 relevant documents\n",
      "   1. Page 495 (similarity: -0.042)\n",
      "   2. Page 624 (similarity: -0.051)\n",
      "   3. Page 410 (similarity: -0.065)\n",
      "   4. Page 112 (similarity: -0.092)\n",
      "   5. Page 410 (similarity: -0.092)\n",
      "\n",
      "📚 EVIDENCE FROM MEDICAL ENCYCLOPEDIA:\n",
      "Found 5 relevant sections from your 637-page encyclopedia\n",
      "\n",
      "📄 **SOURCE 1: PAGE 495**\n",
      "🎯 Relevance: -4.2%\n",
      "──────────────────────────────────────────────────\n",
      "Resources\n",
      "BOOKS\n",
      "Balistreri, William F. “Cholestasis.” In Nelson Textbook of\n",
      "Pediatrics, ed. Richard E. Behrman. Philadelphia: W. B.\n",
      "Saunders Co., 1996.\n",
      "Feldman, Mark, et al. “Diseases of the Bile Ducts.” Sleisenger\n",
      "& Fordtran’s Gastrointestinal and Liver Disease.\n",
      "Philadelphia: W. B. Saunders Co., 1998.\n",
      "PERIODICALS\n",
      "Ryckman, F., R. Fisher, and S. Pedersen, et al. “Improved Sur-\n",
      "vival in Biliary Atresia Patients in the Present Era of Liver\n",
      "Transplantation.” Journal of Pediatric Surgery 28 (1993):\n",
      "382.\n",
      "J. Ricker Polsdorfer, MD\n",
      "Biliary duct cancer see Gallbladder cancer\n",
      "Biliary tract cancer see Bile duct cancer\n",
      "Bilirubin test see Liver function tests\n",
      "Binge-eating disorder\n",
      "Definition\n",
      "Binge eating disorder (BED) is characterized by a\n",
      "loss of control over eating behaviors. The binge eater\n",
      "consumes unnaturally large amounts of food in a short\n",
      "time period, but unlike a bulimic, does not regularly\n",
      "engage in any inappropriate weight-reducing behaviors\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 2: PAGE 624**\n",
      "🎯 Relevance: -5.1%\n",
      "──────────────────────────────────────────────────\n",
      "other surgical techniques may be used. For patients who\n",
      "otherwise would have less than six months to live, liver\n",
      "transplantation is sometimes performed.\n",
      "In a few patients, a “balloon catheter” can open the\n",
      "blocked blood vessels, without the need for major surgery.\n",
      "Drugs\n",
      "Sometimes, anti-clotting drugs such as urokinase\n",
      "can be used for patients with a sudden onset of clotting in\n",
      "the veins of the liver. These drugs do not seem to work\n",
      "when the clots have become established.\n",
      "Prognosis\n",
      "If surgery is done before permanent liver damage sets\n",
      "in, long-term survival is possible. In these cases, damaged\n",
      "liver cells can actually recover. If patients are already very\n",
      "sick with liver disease, the surgery may not be as helpful.\n",
      "Prevention\n",
      "The best approach to prevention is to carefully control\n",
      "the blood disorders that can lead to Budd-Chiari syndrome.\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2\n",
      "610\n",
      "Budd-Chiari syndrome\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 3: PAGE 410**\n",
      "🎯 Relevance: -6.5%\n",
      "──────────────────────────────────────────────────\n",
      "and coronary artery bypass surgery. Atherosclerosis\n",
      "requires lifelong care.\n",
      "Patients who have less severe atherosclerosis may\n",
      "achieve adequate control through lifestyle changes and\n",
      "drug therapy. Many of the lifestyle changes that prevent\n",
      "disease progression—a low-fat, low-cholesterol diet, los-\n",
      "ing weight (if necessary), exercise, controlling blood\n",
      "pressure, and not smoking—also help prevent the disease.\n",
      "Most of the drugs prescribed for atherosclerosis seek\n",
      "to lower cholesterol. Many popular lipid-lowering drugs\n",
      "can reduce LDL-cholesterol by an average of 25-30%\n",
      "when combined with a low-fat, low-cholesterol diet.\n",
      "Lipid-lowering drugs include bile acid resins, “statins”\n",
      "(drugs that effect HMG-CoA reductase, an enzyme that\n",
      "controls the processing of cholesterol), niacin, and fibric\n",
      "acid derivatives such as gemfibrozil (Lobid). Aspirin\n",
      "helps prevent thrombosis and a variety of other medica-\n",
      "tions can be used to treat the effects of atherosclerosis.\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 4: PAGE 112**\n",
      "🎯 Relevance: -9.2%\n",
      "──────────────────────────────────────────────────\n",
      "medications would be helpful unless the patient was also\n",
      "willing to work very hard to change his or her behavior.\n",
      "Alternative treatment\n",
      "Alternative treatments can be a helpful adjunct for the\n",
      "alcoholic patient, once the medical danger of withdrawal\n",
      "has passed. Because many alcoholics have very stressful\n",
      "lives (whether because of or leading to the alcoholism is\n",
      "sometimes a matter of debate), many of the treatments for\n",
      "alcoholism involve dealing with and relieving stress. These\n",
      "include massage, meditation, and hypnotherapy. The\n",
      "malnutrition of long-term alcohol use is addressed by nutri-\n",
      "tion-oriented practitioners with careful attention to a\n",
      "healthy diet and the use of nutritional supplements such as\n",
      "vitamins A, B complex, and C, as well as certain fatty\n",
      "acids, amino acids, zinc, magnesium, and selenium. Herbal\n",
      "treatments include milk thistle(Silybum marianum), which\n",
      "is thought to protect the liver against damage. Other herbs\n",
      "are thought to be helpful for the patient suffering through\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 5: PAGE 410**\n",
      "🎯 Relevance: -9.2%\n",
      "──────────────────────────────────────────────────\n",
      "cardiologist shaves off and removes strips of plaque from\n",
      "the blocked artery. In laser angioplasty, a catheter with a\n",
      "laser tip is inserted to burn or break down the plaque. A\n",
      "metal coil called a stent may be permanently implanted\n",
      "to keep a blocked artery open.\n",
      "Alternative treatment\n",
      "Alternative therapies that focus on diet and lifestyle\n",
      "can help prevent, retard, or reverse atherosclerosis. Herbal\n",
      "therapies that may be helpful include: hawthorn (Cratae-\n",
      "gus laevigata), notoginseng root (Panax notoginseng),\n",
      "garlic (Allium sativum), ginger (Zingiber officinale), hot\n",
      "red or chili peppers, yarrow (Achillea millefolium), and\n",
      "alfalfa (Medicago sativum). Relaxation techniques\n",
      "including yoga, meditation, guided imagery, biofeed-\n",
      "back, and counseling and other “talking” therapies may\n",
      "also be useful to prevent or slow the progress of the dis-\n",
      "ease. Dietary modifications focus on eating foods that are\n",
      "low in fats (especially saturated fats), cholesterol, sugar,\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "⚠️ **Medical Disclaimer:** This information is for educational purposes only.\n",
      "Always consult qualified healthcare professionals for medical advice.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': 'Resources\\nBOOKS\\nBalistreri, William F. “Cholestasis.” In Nelson Textbook of\\nPediatrics, ed. Richard E. Behrman. Philadelphia: W. B.\\nSaunders Co., 1996.\\nFeldman, Mark, et al. “Diseases of the Bile Ducts.” Sleisenger\\n& Fordtran’s Gastrointestinal and Liver Disease.\\nPhiladelphia: W. B. Saunders Co., 1998.\\nPERIODICALS\\nRyckman, F., R. Fisher, and S. Pedersen, et al. “Improved Sur-\\nvival in Biliary Atresia Patients in the Present Era of Liver\\nTransplantation.” Journal of Pediatric Surgery 28 (1993):\\n382.\\nJ. Ricker Polsdorfer, MD\\nBiliary duct cancer see Gallbladder cancer\\nBiliary tract cancer see Bile duct cancer\\nBilirubin test see Liver function tests\\nBinge-eating disorder\\nDefinition\\nBinge eating disorder (BED) is characterized by a\\nloss of control over eating behaviors. The binge eater\\nconsumes unnaturally large amounts of food in a short\\ntime period, but unlike a bulimic, does not regularly\\nengage in any inappropriate weight-reducing behaviors',\n",
       "  'metadata': {'total_pages': 637, 'source': 'Medical_book.pdf', 'page': 495},\n",
       "  'score': -0.04201352596282959},\n",
       " {'content': 'other surgical techniques may be used. For patients who\\notherwise would have less than six months to live, liver\\ntransplantation is sometimes performed.\\nIn a few patients, a “balloon catheter” can open the\\nblocked blood vessels, without the need for major surgery.\\nDrugs\\nSometimes, anti-clotting drugs such as urokinase\\ncan be used for patients with a sudden onset of clotting in\\nthe veins of the liver. These drugs do not seem to work\\nwhen the clots have become established.\\nPrognosis\\nIf surgery is done before permanent liver damage sets\\nin, long-term survival is possible. In these cases, damaged\\nliver cells can actually recover. If patients are already very\\nsick with liver disease, the surgery may not be as helpful.\\nPrevention\\nThe best approach to prevention is to carefully control\\nthe blood disorders that can lead to Budd-Chiari syndrome.\\nGALE ENCYCLOPEDIA OF MEDICINE 2\\n610\\nBudd-Chiari syndrome',\n",
       "  'metadata': {'page': 624, 'source': 'Medical_book.pdf', 'total_pages': 637},\n",
       "  'score': -0.0512160062789917},\n",
       " {'content': 'and coronary artery bypass surgery. Atherosclerosis\\nrequires lifelong care.\\nPatients who have less severe atherosclerosis may\\nachieve adequate control through lifestyle changes and\\ndrug therapy. Many of the lifestyle changes that prevent\\ndisease progression—a low-fat, low-cholesterol diet, los-\\ning weight (if necessary), exercise, controlling blood\\npressure, and not smoking—also help prevent the disease.\\nMost of the drugs prescribed for atherosclerosis seek\\nto lower cholesterol. Many popular lipid-lowering drugs\\ncan reduce LDL-cholesterol by an average of 25-30%\\nwhen combined with a low-fat, low-cholesterol diet.\\nLipid-lowering drugs include bile acid resins, “statins”\\n(drugs that effect HMG-CoA reductase, an enzyme that\\ncontrols the processing of cholesterol), niacin, and fibric\\nacid derivatives such as gemfibrozil (Lobid). Aspirin\\nhelps prevent thrombosis and a variety of other medica-\\ntions can be used to treat the effects of atherosclerosis.',\n",
       "  'metadata': {'total_pages': 637, 'page': 410, 'source': 'Medical_book.pdf'},\n",
       "  'score': -0.06527948379516602},\n",
       " {'content': 'medications would be helpful unless the patient was also\\nwilling to work very hard to change his or her behavior.\\nAlternative treatment\\nAlternative treatments can be a helpful adjunct for the\\nalcoholic patient, once the medical danger of withdrawal\\nhas passed. Because many alcoholics have very stressful\\nlives (whether because of or leading to the alcoholism is\\nsometimes a matter of debate), many of the treatments for\\nalcoholism involve dealing with and relieving stress. These\\ninclude massage, meditation, and hypnotherapy. The\\nmalnutrition of long-term alcohol use is addressed by nutri-\\ntion-oriented practitioners with careful attention to a\\nhealthy diet and the use of nutritional supplements such as\\nvitamins A, B complex, and C, as well as certain fatty\\nacids, amino acids, zinc, magnesium, and selenium. Herbal\\ntreatments include milk thistle(Silybum marianum), which\\nis thought to protect the liver against damage. Other herbs\\nare thought to be helpful for the patient suffering through',\n",
       "  'metadata': {'total_pages': 637, 'source': 'Medical_book.pdf', 'page': 112},\n",
       "  'score': -0.09167039394378662},\n",
       " {'content': 'cardiologist shaves off and removes strips of plaque from\\nthe blocked artery. In laser angioplasty, a catheter with a\\nlaser tip is inserted to burn or break down the plaque. A\\nmetal coil called a stent may be permanently implanted\\nto keep a blocked artery open.\\nAlternative treatment\\nAlternative therapies that focus on diet and lifestyle\\ncan help prevent, retard, or reverse atherosclerosis. Herbal\\ntherapies that may be helpful include: hawthorn (Cratae-\\ngus laevigata), notoginseng root (Panax notoginseng),\\ngarlic (Allium sativum), ginger (Zingiber officinale), hot\\nred or chili peppers, yarrow (Achillea millefolium), and\\nalfalfa (Medicago sativum). Relaxation techniques\\nincluding yoga, meditation, guided imagery, biofeed-\\nback, and counseling and other “talking” therapies may\\nalso be useful to prevent or slow the progress of the dis-\\nease. Dietary modifications focus on eating foods that are\\nlow in fats (especially saturated fats), cholesterol, sugar,',\n",
       "  'metadata': {'source': 'Medical_book.pdf', 'page': 410, 'total_pages': 637},\n",
       "  'score': -0.09176898002624512}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cardiovascular\n",
    "medical_search('heart attack symptoms')\n",
    "\n",
    "# Endocrine\n",
    "medical_search('thyroid disorders')\n",
    "\n",
    "# Respiratory\n",
    "medical_search('fatty liver treatment')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tDyDSWxBwlb3"
   },
   "outputs": [],
   "source": [
    "# import gradio as gr\n",
    "# import socket\n",
    "# import random\n",
    "\n",
    "# def find_free_port(start_port=7860, max_attempts=50):\n",
    "#     \"\"\"Find a free port starting from start_port\"\"\"\n",
    "#     for port in range(start_port, start_port + max_attempts):\n",
    "#         try:\n",
    "#             with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "#                 s.bind(('localhost', port))\n",
    "#                 return port\n",
    "#         except OSError:\n",
    "#             continue\n",
    "#     # If no port found in range, try random ports\n",
    "#     for _ in range(20):\n",
    "#         port = random.randint(8000, 9999)\n",
    "#         try:\n",
    "#             with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "#                 s.bind(('localhost', port))\n",
    "#                 return port\n",
    "#         except OSError:\n",
    "#             continue\n",
    "#     raise OSError(\"Could not find a free port\")\n",
    "\n",
    "# def create_gradio_interface():\n",
    "#     \"\"\"Create enhanced Gradio interface with fallback support\"\"\"\n",
    "\n",
    "#     def process_query(query: str, show_sources: bool = True, num_sources: int = 5, use_ai: bool = True):\n",
    "#         if not query.strip():\n",
    "#             return \"Please enter a medical question.\", \"\", \"\"\n",
    "\n",
    "#         try:\n",
    "#             # Force retrieval-only mode if requested or if Gemini unavailable\n",
    "#             if not use_ai or not rag_system.gemini_available:\n",
    "#                 # Use medical_search function for retrieval-only\n",
    "#                 docs = rag_system.retrieve_documents(query, num_sources)\n",
    "#                 answer = rag_system._format_retrieval_answer(query, docs)\n",
    "#                 processing_time = 0.5  # Estimated time for retrieval\n",
    "#                 gemini_used = False\n",
    "#             else:\n",
    "#                 # Try full RAG with AI\n",
    "#                 result = rag_system.ask(query)\n",
    "#                 answer = result['answer']\n",
    "#                 docs = result['sources']\n",
    "#                 processing_time = result['processing_time']\n",
    "#                 gemini_used = result['gemini_used']\n",
    "\n",
    "#             # Format sources\n",
    "#             sources_text = \"\"\n",
    "#             stats_text = f\"⏱️ Time: {processing_time:.2f}s | 📊 Sources: {len(docs)} | 🤖 AI: {'Yes' if gemini_used else 'No'}\"\n",
    "\n",
    "#             if show_sources:\n",
    "#                 sources_text = \"\\n\\n📚 **SOURCE REFERENCES:**\\n\" + \"=\"*50 + \"\\n\"\n",
    "#                 for i, doc in enumerate(docs, 1):\n",
    "#                     page = doc['metadata'].get('page', '?')\n",
    "#                     score = doc['score']\n",
    "#                     content_preview = doc['content'][:300] + \"...\" if len(doc['content']) > 300 else doc['content']\n",
    "\n",
    "#                     sources_text += f\"\\n**[{i}] 📄 Page {page} | 🎯 Relevance: {score:.3f}**\\n\"\n",
    "#                     sources_text += f\"{content_preview}\\n\"\n",
    "#                     sources_text += \"-\" * 50 + \"\\n\"\n",
    "\n",
    "#             return answer, sources_text, stats_text\n",
    "\n",
    "#         except Exception as e:\n",
    "#             error_msg = f\"❌ Error: {str(e)}\"\n",
    "#             return error_msg, \"\", error_msg\n",
    "\n",
    "#     # Create interface\n",
    "#     with gr.Blocks(\n",
    "#         title=\"Medical Encyclopedia RAG Chatbot\",\n",
    "#         theme=gr.themes.Soft(),\n",
    "#         css=\"\"\"\n",
    "#         .medical-header {\n",
    "#             background: linear-gradient(90deg, #4CAF50, #2196F3);\n",
    "#             color: white;\n",
    "#             padding: 20px;\n",
    "#             border-radius: 10px;\n",
    "#             text-align: center;\n",
    "#             margin-bottom: 20px;\n",
    "#         }\n",
    "#         \"\"\"\n",
    "#     ) as demo:\n",
    "\n",
    "#         # Header with status\n",
    "#         status_indicator = \"🤖 AI Enabled\" if rag_system.gemini_available else \"📚 Retrieval Mode\"\n",
    "#         gr.HTML(f\"\"\"\n",
    "#         <div class=\"medical-header\">\n",
    "#             <h1>🏥 Medical Encyclopedia RAG Chatbot</h1>\n",
    "#             <p>Ask evidence-based medical questions • {status_indicator} • 637-page Medical Encyclopedia</p>\n",
    "#         </div>\n",
    "#         \"\"\")\n",
    "\n",
    "#         with gr.Row():\n",
    "#             with gr.Column(scale=2):\n",
    "#                 gr.Markdown(\"### 🔍 Ask Your Medical Question\")\n",
    "\n",
    "#                 query_input = gr.Textbox(\n",
    "#                     label=\"Medical Question\",\n",
    "#                     placeholder=\"e.g., What are the symptoms and treatment options for diabetes?\",\n",
    "#                     lines=3\n",
    "#                 )\n",
    "\n",
    "#                 with gr.Row():\n",
    "#                     submit_btn = gr.Button(\"🔍 Search & Answer\", variant=\"primary\", size=\"lg\")\n",
    "#                     clear_btn = gr.Button(\"🗑️ Clear\", variant=\"secondary\")\n",
    "\n",
    "#                 with gr.Accordion(\"⚙️ Search Options\", open=False):\n",
    "#                     show_sources = gr.Checkbox(label=\"Show source references\", value=True)\n",
    "#                     num_sources = gr.Slider(1, 10, value=5, step=1, label=\"Number of sources\")\n",
    "#                     use_ai = gr.Checkbox(\n",
    "#                         label=\"Use AI generation (if available)\",\n",
    "#                         value=rag_system.gemini_available,\n",
    "#                         interactive=rag_system.gemini_available\n",
    "#                     )\n",
    "\n",
    "#             with gr.Column(scale=3):\n",
    "#                 gr.Markdown(\"### 🤖 Medical Information Response\")\n",
    "\n",
    "#                 answer_output = gr.Textbox(\n",
    "#                     label=\"Medical Information\",\n",
    "#                     lines=12,\n",
    "#                     max_lines=20,\n",
    "#                     show_copy_button=True\n",
    "#                 )\n",
    "\n",
    "#                 stats_output = gr.Textbox(label=\"Query Statistics\", lines=1)\n",
    "#                 sources_output = gr.Textbox(label=\"Source References\", lines=8, show_copy_button=True)\n",
    "\n",
    "#         # Event handlers\n",
    "#         submit_btn.click(\n",
    "#             process_query,\n",
    "#             inputs=[query_input, show_sources, num_sources, use_ai],\n",
    "#             outputs=[answer_output, sources_output, stats_output]\n",
    "#         )\n",
    "\n",
    "#         query_input.submit(\n",
    "#             process_query,\n",
    "#             inputs=[query_input, show_sources, num_sources, use_ai],\n",
    "#             outputs=[answer_output, sources_output, stats_output]\n",
    "#         )\n",
    "\n",
    "#         clear_btn.click(lambda: (\"\", \"\", \"\", \"\"), outputs=[query_input, answer_output, sources_output, stats_output])\n",
    "\n",
    "#         # Example queries\n",
    "#         gr.Markdown(\"### 💡 Example Medical Questions\")\n",
    "#         examples = [\n",
    "#             \"What are the symptoms of diabetes?\",\n",
    "#             \"How is hypertension treated?\",\n",
    "#             \"What causes heart disease?\",\n",
    "#             \"What are the side effects of aspirin?\",\n",
    "#             \"How do antibiotics work?\",\n",
    "#             \"What is the anatomy of the heart?\",\n",
    "#             \"Symptoms of heart attack vs stroke\",\n",
    "#             \"Treatment options for cancer\"\n",
    "#         ]\n",
    "\n",
    "#         with gr.Row():\n",
    "#             for example in examples[:4]:\n",
    "#                 gr.Button(example, size=\"sm\").click(lambda x=example: x, outputs=query_input)\n",
    "\n",
    "#         with gr.Row():\n",
    "#             for example in examples[4:]:\n",
    "#                 gr.Button(example, size=\"sm\").click(lambda x=example: x, outputs=query_input)\n",
    "\n",
    "#         # Disclaimer\n",
    "#         gr.Markdown(\"\"\"\n",
    "#         ---\n",
    "#         ### ⚠️ Important Medical Disclaimer\n",
    "#         **This AI assistant is for educational and informational purposes only:**\n",
    "#         - 🩺 Always consult qualified healthcare professionals for medical advice\n",
    "#         - 🚨 Not a substitute for professional medical diagnosis or treatment\n",
    "#         - 📚 Information based on medical encyclopedia content only\n",
    "#         - ⚕️ For emergencies, contact emergency services immediately\n",
    "#         \"\"\")\n",
    "\n",
    "#     return demo\n",
    "\n",
    "# # Launch interface with dynamic port finding\n",
    "# print(\"🌐 Creating enhanced Gradio interface...\")\n",
    "# demo = create_gradio_interface()\n",
    "\n",
    "# print(\"✅ Interface ready with fallback support!\")\n",
    "# print(\"🔍 Finding available port...\")\n",
    "\n",
    "# try:\n",
    "#     free_port = find_free_port()\n",
    "#     print(f\"🚀 Launching on port {free_port}...\")\n",
    "\n",
    "#     demo.launch(\n",
    "#         share=True,\n",
    "#         server_name=\"0.0.0.0\",\n",
    "#         server_port=free_port,\n",
    "#         show_error=True,\n",
    "#         quiet=False\n",
    "#     )\n",
    "# except Exception as e:\n",
    "#     print(f\"❌ Error launching Gradio: {e}\")\n",
    "#     print(\"💡 Try manually specifying a different port:\")\n",
    "#     print(\"demo.launch(server_port=8080)  # or any other available port\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "bca5a0d7f286466496edf44d0f6f63c2",
      "7d714172a4964235ac1cd090404ae720",
      "6a96bf958b3c440383610b4d14468afd",
      "8fcaaa85c2ab4ca2a2f6c3b61103b517",
      "f3d2d75e95524b028de92764c32071bf",
      "107d00aec3054ec5b1203b537fa183b4",
      "d069797bbad7433f95ae8f788e09928c",
      "5ad5548295e64a9ab51f1aa45c5877c7",
      "9eef487225bc4347ac1258db9fd7df47",
      "03e0cd58f58b44fab85379c03bd88e2f",
      "9b78589ee1ce406a9bc2254bb8e3f68c",
      "dc00c73b5d784817872a4fdd9ef68be2",
      "694cc222009b4de7a053d06a8cef96fd",
      "05733747aff64b0ebac6878d27d07d31",
      "54263951fe6b48e190f05f09ea30fa2c",
      "3c027e50590c43fb9b90494020988357",
      "4f3e2d6924314120a992ae2cf251058a",
      "a30f8a262de945d78d5840b15f70f8b1",
      "37b11c50305847dbba8d8909ffe745ee",
      "d46945b6cdd447ac95b8438c53484141",
      "6bffce59d3d44dfc900f0e916e90c6a8",
      "7955fbf60f6c488cae3cd873404f6f01"
     ]
    },
    "id": "-aDo80OozeSc",
    "outputId": "7031525a-12ae-48d2-8c15-94ab24e217d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 **QUICK TESTS** - Try these functions:\n",
      "\n",
      "1. Testing medical search...\n",
      "🏥 MEDICAL ENCYCLOPEDIA SEARCH\n",
      "============================================================\n",
      "Question: diabetes symptoms\n",
      "============================================================\n",
      "🔍 Searching for: 'diabetes symptoms'\n",
      "🔄 Creating embeddings for 1 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca5a0d7f286466496edf44d0f6f63c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created embeddings with shape: (1, 384)\n",
      "✅ Retrieved 3 relevant documents\n",
      "   1. Page 543 (similarity: 0.057)\n",
      "   2. Page 277 (similarity: 0.030)\n",
      "   3. Page 544 (similarity: -0.040)\n",
      "\n",
      "📚 EVIDENCE FROM MEDICAL ENCYCLOPEDIA:\n",
      "Found 3 relevant sections from your 637-page encyclopedia\n",
      "\n",
      "📄 **SOURCE 1: PAGE 543**\n",
      "🎯 Relevance: 5.7%\n",
      "──────────────────────────────────────────────────\n",
      "begin to fall. A person with diabetes mellitus either does\n",
      "not make enough insulin, or makes insulin that does not\n",
      "work properly. The result is blood sugar that remains\n",
      "high, a condition called hyperglycemia.\n",
      "Diabetes must be diagnosed as early as possible. If\n",
      "left untreated, it can damage or cause failure of the eyes,\n",
      "kidneys, nerves, heart, blood vessels, and other body\n",
      "organs. Hypoglycemia, or low blood sugar, may also be\n",
      "discovered through blood sugar testing. Hypoglycemia is\n",
      "caused by various hormone disorders and liver disease,\n",
      "as well as by too much insulin.\n",
      "Description\n",
      "There are a variety of ways to measure a person’s\n",
      "blood sugar.\n",
      "Whole blood glucose test\n",
      "Whole blood glucose testing can be performed by a\n",
      "person in his or her home, and kits are available for this\n",
      "purpose. The person pricks his or her finger (a finger\n",
      "stick) with a sterile sharp blade from the kit. A single\n",
      "drop of blood is placed on a strip in a portable instrument\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 2: PAGE 277**\n",
      "🎯 Relevance: 3.0%\n",
      "──────────────────────────────────────────────────\n",
      "263\n",
      "Antidiabetic drugs\n",
      "Antidiabetic Drugs\n",
      "Brand Name(Generic Name)\n",
      "Possible Common Side Effects Include:\n",
      "Diabinese (chlorpropamide)\n",
      "Diarrhea, nausea, loss of appetite\n",
      "Glucotrol (glipizide)\n",
      "Dizziness, fatigue, headache, nervousness\n",
      "*Insulin\n",
      "Mild allergic reactions, decreased blood pressure, rash, shortness of breath\n",
      "Micronase (glyburide)\n",
      "Nausea, heartburn, bloating\n",
      "orinase (tolbutamide)\n",
      "Nausea, heartburn, bloating\n",
      "*Insulin is the generic name for several brands which may be animal-based, human-based, or synthetic.\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "📄 **SOURCE 3: PAGE 544**\n",
      "🎯 Relevance: -4.0%\n",
      "──────────────────────────────────────────────────\n",
      "200 mg/dL\n",
      "• casual plasma glucose test (nonfasting, with symptoms)\n",
      "less than or equal to 200 mg/dL\n",
      "• gestational oral glucose tolerance test, 1 hour less than\n",
      "or equal to 140 mg/dL\n",
      "Brain damage can occur from glucose levels below\n",
      "40 mg/dL and coma from levels above 470 mg/dL.\n",
      "Other hormone disorders can cause both hyper-\n",
      "glycemia and hypoglycemia. Abnormal results must be\n",
      "interpreted by a doctor who is aware of the person’s med-\n",
      "ical condition and medical history.\n",
      "Resources\n",
      "BOOKS\n",
      "A Manual of Laboratory and Diagnostic Tests. 5th ed. Ed.\n",
      "Francis Fishback. Philadelphia: Lippincott, 1996.\n",
      "Henry, John B., ed. Clinical Diagnosis and Management by\n",
      "Laboratory Methods. 19th ed. Philadelphia: W. B. Saun-\n",
      "ders Co., 1996.\n",
      "PERIODICALS\n",
      "American Diabetes Association. “Report of the Expert Com-\n",
      "mittee on the Diagnosis and Classification of Diabetes\n",
      "Mellitus.” Diabetes Care 20, no, 7(July 997): 1183-1197.\n",
      "ORGANIZATIONS\n",
      "American Diabetes Association. 1701 North Beauregard Street,\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "⚠️ **Medical Disclaimer:** This information is for educational purposes only.\n",
      "Always consult qualified healthcare professionals for medical advice.\n",
      "\n",
      "\n",
      "============================================================\n",
      "2. Testing quick query...\n",
      "❓ **Question:** What causes hypertension?\n",
      "============================================================\n",
      "🔍 Searching for: 'What causes hypertension?'\n",
      "🔄 Creating embeddings for 1 texts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc00c73b5d784817872a4fdd9ef68be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created embeddings with shape: (1, 384)\n",
      "✅ Retrieved 5 relevant documents\n",
      "   1. Page 219 (similarity: 0.165)\n",
      "   2. Page 115 (similarity: -0.018)\n",
      "   3. Page 143 (similarity: -0.030)\n",
      "   4. Page 249 (similarity: -0.033)\n",
      "   5. Page 408 (similarity: -0.042)\n",
      "🤖 **ANSWER:**\n",
      "According to Source 1, page 219,  angiotensin II, produced by the conversion of angiotensin I by ACE (angiotensin-converting enzyme), causes narrowing of blood vessels, increasing blood pressure.  Additionally, angiotensin II stimulates aldosterone, further increasing blood pressure.  Certain kidney disorders can also increase angiotensin II production, contributing to hypertension.  Source 3, page 143, states that high blood pressure (hypertension) puts strain on the heart and arteries, and over time can cause damage leading to stroke, heart failure, or kidney failure.  Source 2, page 115 mentions elevated aldosterone levels are seen in secondary aldosteronism, stress, and malignant hypertension.  Please consult a healthcare professional for diagnosis and treatment.\n",
      "\n",
      "\n",
      "⏱️ Processing time: 1.72 seconds\n",
      "🔧 Method: AI + Retrieval\n",
      "\n",
      "============================================================\n",
      "🎉 **YOUR MEDICAL RAG SYSTEM IS WORKING!**\n",
      "\n",
      "💡 **Available Functions:**\n",
      "• medical_search('question', num_results) - Detailed search\n",
      "• quick_query('question') - Fast answer\n",
      "• system_diagnostic() - Check system status\n",
      "\n",
      "📊 **System Status:**\n",
      "• Database: 3,391 medical text chunks ready\n",
      "• Retrieval: ✅ Working perfectly\n",
      "• AI Generation: ✅ Available\n"
     ]
    }
   ],
   "source": [
    "print(\"🧪 **QUICK TESTS** - Try these functions:\")\n",
    "\n",
    "# Test the working retrieval system\n",
    "print(\"\\n1. Testing medical search...\")\n",
    "medical_search(\"diabetes symptoms\", 3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. Testing quick query...\")\n",
    "quick_query(\"What causes hypertension?\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 **YOUR MEDICAL RAG SYSTEM IS WORKING!**\")\n",
    "print(\"\\n💡 **Available Functions:**\")\n",
    "print(\"• medical_search('question', num_results) - Detailed search\")\n",
    "print(\"• quick_query('question') - Fast answer\")\n",
    "print(\"• system_diagnostic() - Check system status\")\n",
    "\n",
    "print(f\"\\n📊 **System Status:**\")\n",
    "print(f\"• Database: {collection.count():,} medical text chunks ready\")\n",
    "print(f\"• Retrieval: ✅ Working perfectly\")\n",
    "print(f\"• AI Generation: {'✅ Available' if rag_system.gemini_available else '📚 Retrieval-only mode'}\")\n",
    "#print(f\"• Web Interface: ✅ Running at your Gradio URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JR0zEkeF0Oof"
   },
   "outputs": [],
   "source": [
    "# def export_vector_db():\n",
    "#     \"\"\"Export ChromaDB for local use\"\"\"\n",
    "#     import zipfile\n",
    "#     from google.colab import files\n",
    "\n",
    "#     if os.path.exists(Config.CHROMA_PERSIST_DIR):\n",
    "#         print(\"📦 Creating vector database export...\")\n",
    "\n",
    "#         zip_path = \"medical_rag_vectordb.zip\"\n",
    "#         with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "#             for root, dirs, file_list in os.walk(Config.CHROMA_PERSIST_DIR):\n",
    "#                 for file in file_list:\n",
    "#                     file_path = os.path.join(root, file)\n",
    "#                     arc_path = os.path.relpath(file_path, Config.CHROMA_PERSIST_DIR)\n",
    "#                     zipf.write(file_path, f\"chroma_db/{arc_path}\")\n",
    "\n",
    "#         zip_size = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "#         print(f\"✅ Export ready: {zip_path} ({zip_size:.1f} MB)\")\n",
    "\n",
    "#         files.download(zip_path)\n",
    "#         print(\"📥 Download started! Use this with local RAG setups.\")\n",
    "\n",
    "#     else:\n",
    "#         print(\"❌ No vector database found to export\")\n",
    "\n",
    "# def show_database_stats():\n",
    "#     \"\"\"Show detailed database statistics\"\"\"\n",
    "#     print(\"📊 MEDICAL RAG DATABASE STATISTICS\")\n",
    "#     print(\"=\"*50)\n",
    "#     print(f\"📚 Collection: {Config.COLLECTION_NAME}\")\n",
    "#     print(f\"💾 Storage: {Config.CHROMA_PERSIST_DIR}\")\n",
    "#     print(f\"🔢 Total documents: {collection.count():,}\")\n",
    "#     print(f\"🔍 Embedding model: {Config.EMBEDDING_MODEL}\")\n",
    "#     print(f\"📐 Embedding dimension: {embedding_manager.model.get_sentence_embedding_dimension()}\")\n",
    "#     print(f\"⚙️ Chunk size: {Config.CHUNK_SIZE:,} characters\")\n",
    "#     print(f\"🔄 Chunk overlap: {Config.CHUNK_OVERLAP} characters\")\n",
    "#     print(f\"🎯 Default retrieval: {Config.TOP_K_RESULTS} documents\")\n",
    "\n",
    "#     # Sample some documents to show variety\n",
    "#     sample_docs = rag_system.retrieve_documents(\"medical\", 3)\n",
    "#     print(f\"\\n📋 Sample document pages: \", end=\"\")\n",
    "#     pages = [str(doc['metadata']['page']) for doc in sample_docs]\n",
    "#     print(\", \".join(pages))\n",
    "\n",
    "# def search_by_page(page_number: int):\n",
    "#     \"\"\"Find documents from a specific page\"\"\"\n",
    "#     print(f\"📄 Searching for content from page {page_number}...\")\n",
    "\n",
    "#     # Query ChromaDB for specific page\n",
    "#     results = collection.get(\n",
    "#         where={\"page\": page_number},\n",
    "#         include=['documents', 'metadatas']\n",
    "#     )\n",
    "\n",
    "#     if results['documents']:\n",
    "#         print(f\"✅ Found {len(results['documents'])} chunks from page {page_number}\")\n",
    "#         for i, doc in enumerate(results['documents']):\n",
    "#             print(f\"\\nChunk {i+1}:\")\n",
    "#             print(\"-\" * 30)\n",
    "#             preview = doc[:300] + \"...\" if len(doc) > 300 else doc\n",
    "#             print(preview)\n",
    "#     else:\n",
    "#         print(f\"❌ No content found for page {page_number}\")\n",
    "\n",
    "# def find_pages_about(topic: str, threshold: float = 0.1):\n",
    "#     \"\"\"Find all pages that mention a specific medical topic\"\"\"\n",
    "#     print(f\"🔍 Finding pages about '{topic}'...\")\n",
    "\n",
    "#     docs = rag_system.retrieve_documents(topic, 20)  # Get more results\n",
    "#     relevant_pages = set()\n",
    "\n",
    "#     for doc in docs:\n",
    "#         if doc['score'] > threshold:\n",
    "#             relevant_pages.add(doc['metadata']['page'])\n",
    "\n",
    "#     sorted_pages = sorted(list(relevant_pages))\n",
    "#     print(f\"📚 Found {len(sorted_pages)} pages about '{topic}': {sorted_pages}\")\n",
    "#     return sorted_pages\n",
    "\n",
    "# def compare_treatments(condition1: str, condition2: str):\n",
    "#     \"\"\"Compare treatments for two medical conditions\"\"\"\n",
    "#     print(f\"⚖️ COMPARING TREATMENTS: {condition1} vs {condition2}\")\n",
    "#     print(\"=\"*60)\n",
    "\n",
    "#     # Search for each condition\n",
    "#     docs1 = rag_system.retrieve_documents(f\"{condition1} treatment\", 3)\n",
    "#     docs2 = rag_system.retrieve_documents(f\"{condition2} treatment\", 3)\n",
    "\n",
    "#     print(f\"📋 **{condition1.upper()} TREATMENT:**\")\n",
    "#     for doc in docs1:\n",
    "#         page = doc['metadata']['page']\n",
    "#         score = doc['score']\n",
    "#         preview = doc['content'][:200] + \"...\"\n",
    "#         print(f\"Page {page} ({score:.1%}): {preview}\")\n",
    "#         print()\n",
    "\n",
    "#     print(f\"📋 **{condition2.upper()} TREATMENT:**\")\n",
    "#     for doc in docs2:\n",
    "#         page = doc['metadata']['page']\n",
    "#         score = doc['score']\n",
    "#         preview = doc['content'][:200] + \"...\"\n",
    "#         print(f\"Page {page} ({score:.1%}): {preview}\")\n",
    "#         print()\n",
    "\n",
    "# def medical_terminology_search(term: str):\n",
    "#     \"\"\"Search for medical terminology definitions\"\"\"\n",
    "#     print(f\"🔬 MEDICAL TERMINOLOGY: '{term}'\")\n",
    "#     print(\"=\"*40)\n",
    "\n",
    "#     # Search for the term\n",
    "#     docs = rag_system.retrieve_documents(f\"what is {term} definition\", 5)\n",
    "\n",
    "#     best_match = docs[0] if docs else None\n",
    "#     if best_match and best_match['score'] > 0.1:\n",
    "#         page = best_match['metadata']['page']\n",
    "#         content = best_match['content']\n",
    "\n",
    "#         print(f\"📖 **Definition found on Page {page}:**\")\n",
    "#         print(content[:500] + (\"...\" if len(content) > 500 else \"\"))\n",
    "#     else:\n",
    "#         print(f\"❌ No clear definition found for '{term}'\")\n",
    "#         print(\"📋 Related content:\")\n",
    "#         for doc in docs[:3]:\n",
    "#             page = doc['metadata']['page']\n",
    "#             preview = doc['content'][:150] + \"...\"\n",
    "#             print(f\"Page {page}: {preview}\")\n",
    "\n",
    "# def symptom_checker(symptoms: List[str]):\n",
    "#     \"\"\"Check what conditions might be associated with given symptoms\"\"\"\n",
    "#     print(f\"🩺 SYMPTOM ANALYSIS\")\n",
    "#     print(\"=\"*30)\n",
    "#     print(f\"Symptoms: {', '.join(symptoms)}\")\n",
    "#     print(\"=\"*30)\n",
    "\n",
    "#     all_docs = []\n",
    "#     for symptom in symptoms:\n",
    "#         docs = rag_system.retrieve_documents(f\"{symptom} symptoms disease\", 3)\n",
    "#         all_docs.extend(docs)\n",
    "\n",
    "#     # Group by page to find common conditions\n",
    "#     page_scores = {}\n",
    "#     for doc in all_docs:\n",
    "#         page = doc['metadata']['page']\n",
    "#         if page in page_scores:\n",
    "#             page_scores[page] = max(page_scores[page], doc['score'])\n",
    "#         else:\n",
    "#             page_scores[page] = doc['score']\n",
    "\n",
    "#     # Sort by relevance\n",
    "#     sorted_pages = sorted(page_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#     print(\"📋 **Possible conditions to investigate:**\")\n",
    "#     for page, score in sorted_pages[:5]:\n",
    "#         if score > 0.05:  # Only show relevant matches\n",
    "#             # Get content for this page\n",
    "#             page_docs = [doc for doc in all_docs if doc['metadata']['page'] == page]\n",
    "#             if page_docs:\n",
    "#                 preview = page_docs[0]['content'][:200] + \"...\"\n",
    "#                 print(f\"Page {page} ({score:.1%}): {preview}\")\n",
    "#                 print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "foOUsjj-0fx7"
   },
   "outputs": [],
   "source": [
    "# def drug_interaction_search(drug1: str, drug2: str = None):\n",
    "#     \"\"\"Search for drug information and interactions\"\"\"\n",
    "#     if drug2:\n",
    "#         query = f\"{drug1} {drug2} interaction side effects\"\n",
    "#         print(f\"💊 DRUG INTERACTION SEARCH: {drug1} + {drug2}\")\n",
    "#     else:\n",
    "#         query = f\"{drug1} side effects contraindications\"\n",
    "#         print(f\"💊 DRUG INFORMATION: {drug1}\")\n",
    "\n",
    "#     print(\"=\"*50)\n",
    "\n",
    "#     docs = rag_system.retrieve_documents(query, 5)\n",
    "\n",
    "#     for i, doc in enumerate(docs, 1):\n",
    "#         if doc['score'] > 0.05:  # Only show relevant results\n",
    "#             page = doc['metadata']['page']\n",
    "#             score = doc['score']\n",
    "#             content = doc['content']\n",
    "\n",
    "#             print(f\"📄 **Source {i} - Page {page} ({score:.1%})**\")\n",
    "\n",
    "#             # Look for key drug information\n",
    "#             sentences = content.split('. ')\n",
    "#             relevant_sentences = []\n",
    "\n",
    "#             search_terms = [drug1.lower()]\n",
    "#             if drug2:\n",
    "#                 search_terms.append(drug2.lower())\n",
    "\n",
    "#             for sentence in sentences:\n",
    "#                 if any(term in sentence.lower() for term in search_terms):\n",
    "#                     relevant_sentences.append(sentence.strip())\n",
    "\n",
    "#             if relevant_sentences:\n",
    "#                 for sentence in relevant_sentences[:3]:  # Show top 3 relevant sentences\n",
    "#                     print(f\"• {sentence}\")\n",
    "#             else:\n",
    "#                 # Fallback to content preview\n",
    "#                 print(doc['content'][:300] + \"...\")\n",
    "\n",
    "#             print()\n",
    "\n",
    "# def anatomy_explorer(body_part: str):\n",
    "#     \"\"\"Explore anatomy of a specific body part\"\"\"\n",
    "#     print(f\"🫀 ANATOMY EXPLORER: {body_part}\")\n",
    "#     print(\"=\"*40)\n",
    "\n",
    "#     queries = [\n",
    "#         f\"{body_part} anatomy structure\",\n",
    "#         f\"{body_part} function physiology\",\n",
    "#         f\"{body_part} location\"\n",
    "#     ]\n",
    "\n",
    "#     all_docs = []\n",
    "#     for query in queries:\n",
    "#         docs = rag_system.retrieve_documents(query, 3)\n",
    "#         all_docs.extend(docs)\n",
    "\n",
    "#     # Remove duplicates and sort by relevance\n",
    "#     seen_pages = set()\n",
    "#     unique_docs = []\n",
    "#     for doc in all_docs:\n",
    "#         page = doc['metadata']['page']\n",
    "#         if page not in seen_pages:\n",
    "#             seen_pages.add(page)\n",
    "#             unique_docs.append(doc)\n",
    "\n",
    "#     unique_docs.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "#     print(f\"📖 **Anatomical information about {body_part}:**\")\n",
    "#     for doc in unique_docs[:5]:\n",
    "#         if doc['score'] > 0.08:\n",
    "#             page = doc['metadata']['page']\n",
    "#             score = doc['score']\n",
    "#             print(f\"\\n📄 Page {page} ({score:.1%}):\")\n",
    "#             print(doc['content'][:400] + \"...\")\n",
    "\n",
    "# def disease_progression_search(disease: str):\n",
    "#     \"\"\"Search for information about disease progression and stages\"\"\"\n",
    "#     print(f\"📈 DISEASE PROGRESSION: {disease}\")\n",
    "#     print(\"=\"*40)\n",
    "\n",
    "#     queries = [\n",
    "#         f\"{disease} stages progression\",\n",
    "#         f\"{disease} early late symptoms\",\n",
    "#         f\"{disease} prognosis outcome\"\n",
    "#     ]\n",
    "\n",
    "#     for i, query in enumerate(queries, 1):\n",
    "#         print(f\"\\n**{i}. {query.title()}:**\")\n",
    "#         docs = rag_system.retrieve_documents(query, 2)\n",
    "\n",
    "#         for doc in docs:\n",
    "#             if doc['score'] > 0.1:\n",
    "#                 page = doc['metadata']['page']\n",
    "#                 preview = doc['content'][:250] + \"...\"\n",
    "#                 print(f\"Page {page}: {preview}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "urRoJOjg0kSk"
   },
   "outputs": [],
   "source": [
    "# def batch_medical_search(questions: List[str]):\n",
    "#     \"\"\"Process multiple medical questions at once\"\"\"\n",
    "#     print(\"🔄 BATCH MEDICAL SEARCH\")\n",
    "#     print(\"=\"*40)\n",
    "\n",
    "#     results = []\n",
    "#     for i, question in enumerate(questions, 1):\n",
    "#         print(f\"\\n{i}. {question}\")\n",
    "#         print(\"-\" * 30)\n",
    "\n",
    "#         result = rag_system.ask(question)\n",
    "#         results.append(result)\n",
    "\n",
    "#         print(f\"⏱️ Time: {result['processing_time']:.2f}s\")\n",
    "#         print(f\"📊 Sources: {len(result['sources'])}\")\n",
    "\n",
    "#         # Show brief answer\n",
    "#         answer_preview = result['answer'][:200] + \"...\" if len(result['answer']) > 200 else result['answer']\n",
    "#         print(f\"📝 Answer: {answer_preview}\")\n",
    "#         print()\n",
    "\n",
    "#     return results\n",
    "\n",
    "# def create_medical_report(topic: str):\n",
    "#     \"\"\"Create a comprehensive medical report on a topic\"\"\"\n",
    "#     print(f\"📋 COMPREHENSIVE MEDICAL REPORT: {topic}\")\n",
    "#     print(\"=\"*60)\n",
    "\n",
    "#     # Different aspects to research\n",
    "#     aspects = [\n",
    "#         f\"{topic} definition causes\",\n",
    "#         f\"{topic} symptoms signs\",\n",
    "#         f\"{topic} diagnosis tests\",\n",
    "#         f\"{topic} treatment management\",\n",
    "#         f\"{topic} prevention complications\"\n",
    "#     ]\n",
    "\n",
    "#     report_sections = []\n",
    "\n",
    "#     for aspect in aspects:\n",
    "#         section_name = aspect.split()[1]  # Extract the aspect name\n",
    "#         docs = rag_system.retrieve_documents(aspect, 3)\n",
    "\n",
    "#         if docs and docs[0]['score'] > 0.05:\n",
    "#             report_sections.append({\n",
    "#                 'title': section_name.title(),\n",
    "#                 'content': docs[0]['content'][:500] + \"...\",\n",
    "#                 'page': docs[0]['metadata']['page'],\n",
    "#                 'score': docs[0]['score']\n",
    "#             })\n",
    "\n",
    "#     # Generate report\n",
    "#     print(f\"**MEDICAL REPORT: {topic.upper()}**\")\n",
    "#     print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "#     print(\"=\"*60)\n",
    "\n",
    "#     for section in report_sections:\n",
    "#         print(f\"\\n**{section['title']} (Page {section['page']})**\")\n",
    "#         print(section['content'])\n",
    "#         print()\n",
    "\n",
    "#     print(\"⚠️ This report is for educational purposes only. Consult healthcare professionals for medical advice.\")\n",
    "\n",
    "#     return report_sections\n",
    "\n",
    "# def trending_medical_topics():\n",
    "#     \"\"\"Find the most referenced medical topics in your encyclopedia\"\"\"\n",
    "#     print(\"📊 TRENDING MEDICAL TOPICS ANALYSIS\")\n",
    "#     print(\"=\"*40)\n",
    "\n",
    "#     common_terms = [\n",
    "#         \"diabetes\", \"hypertension\", \"cancer\", \"heart disease\",\n",
    "#         \"infection\", \"inflammation\", \"treatment\", \"medication\",\n",
    "#         \"symptoms\", \"diagnosis\", \"therapy\", \"surgery\"\n",
    "#     ]\n",
    "\n",
    "#     topic_scores = {}\n",
    "\n",
    "#     for term in common_terms:\n",
    "#         docs = rag_system.retrieve_documents(term, 10)\n",
    "#         if docs:\n",
    "#             # Calculate average relevance score\n",
    "#             avg_score = sum(doc['score'] for doc in docs) / len(docs)\n",
    "#             topic_scores[term] = {\n",
    "#                 'avg_score': avg_score,\n",
    "#                 'pages': len(set(doc['metadata']['page'] for doc in docs)),\n",
    "#                 'top_score': docs[0]['score'] if docs else 0\n",
    "#             }\n",
    "\n",
    "#     # Sort by relevance\n",
    "#     sorted_topics = sorted(topic_scores.items(), key=lambda x: x[1]['avg_score'], reverse=True)\n",
    "\n",
    "#     print(\"📈 **Most Covered Medical Topics:**\")\n",
    "#     for topic, stats in sorted_topics[:8]:\n",
    "#         print(f\"• {topic.title()}: {stats['pages']} pages, avg relevance {stats['avg_score']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JXxpgLAK0v8o",
    "outputId": "6ad57056-d6c9-4a1b-c379-f8cdcc6ec42e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat) (4.25.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat) (5.7.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (0.27.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.14.1)\n",
      "❌ Error: [Errno 2] No such file or directory: 'medibot_prototype.ipynb'\n",
      "File might not exist in current directory\n",
      "ls: cannot access '*.ipynb': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Install required package if not available\n",
    "!pip install nbformat\n",
    "\n",
    "# Clear widget metadata to fix upload error\n",
    "import json\n",
    "import nbformat\n",
    "from google.colab import files\n",
    "\n",
    "# Your notebook name (keeping the same name)\n",
    "notebook_name = 'medibot_prototype.ipynb'\n",
    "\n",
    "try:\n",
    "    # Read current notebook\n",
    "    with open(notebook_name, 'r') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    # Remove problematic widgets metadata\n",
    "    if 'widgets' in nb.metadata:\n",
    "        del nb.metadata['widgets']\n",
    "        print(\"✅ Removed widgets metadata\")\n",
    "\n",
    "    # Also clear any cell-level widget state\n",
    "    widgets_removed = 0\n",
    "    for cell in nb.cells:\n",
    "        if hasattr(cell, 'metadata') and 'widgets' in cell.metadata:\n",
    "            del cell.metadata['widgets']\n",
    "            widgets_removed += 1\n",
    "\n",
    "    if widgets_removed > 0:\n",
    "        print(f\"✅ Removed widgets from {widgets_removed} cells\")\n",
    "\n",
    "    # Save back to the same file name\n",
    "    with open(notebook_name, 'w') as f:\n",
    "        nbformat.write(nb, f)\n",
    "\n",
    "    print(f\"✅ Fixed! Download the same file: {notebook_name}\")\n",
    "\n",
    "    # Download the fixed version (same name)\n",
    "    files.download(notebook_name)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    print(\"File might not exist in current directory\")\n",
    "    # List files to check\n",
    "    !ls *.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qiyH7b91AuZ",
    "outputId": "cddf2ef7-d0fb-4253-ed98-0e7464968479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory files:\n",
      "  .config\n",
      "  Medical_book.pdf\n",
      "  chroma_db\n",
      "  Medical_book (1).pdf\n",
      "  .gradio\n",
      "  sample_data\n",
      "\n",
      "==================================================\n",
      "Searching for .ipynb files...\n"
     ]
    }
   ],
   "source": [
    "# Check what files are in the current directory\n",
    "import os\n",
    "print(\"Current directory files:\")\n",
    "for file in os.listdir('.'):\n",
    "    print(f\"  {file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Search for any .ipynb files in the system\n",
    "print(\"Searching for .ipynb files...\")\n",
    "!find /content -name \"*.ipynb\" 2>/dev/null | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeIQzD5i2Hk1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
